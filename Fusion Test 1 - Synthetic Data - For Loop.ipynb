{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba2dffb",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macOS\n",
      "Interactive plot activated\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import platform\n",
    "import random\n",
    "from tkinter import Tk\n",
    "\n",
    "from itertools import permutations\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, models,datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Extend width of Jupyter Notebook Cell to the size of browser\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# OS related settings\n",
    "if platform.system() == 'Windows':\n",
    "    print('Windows')\n",
    "#     %matplotlib tk\n",
    "    %matplotlib qt\n",
    "elif platform.system() == 'Darwin':\n",
    "    print('macOS')\n",
    "    Tk().withdraw()\n",
    "    %matplotlib osx\n",
    "elif platform == 'linux' or platform == 'linux2':\n",
    "    print('Linux')\n",
    "# This line of \"print\" must exist right after %matplotlib command, otherwise JN will hang on the first import statement after this.\n",
    "print('Interactive plot activated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6636ac83",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ChIQP\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "from cvxopt import solvers, matrix\n",
    "\n",
    "\n",
    "\n",
    "# Silencing solvers.qp\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "from io import StringIO\n",
    "class NullIO(StringIO):\n",
    "    def write(self, txt):\n",
    "        pass\n",
    "\n",
    "\n",
    "def silent(fn):\n",
    "    \"\"\"Decorator to silence functions.\"\"\"\n",
    "    def silent_fn(*args, **kwargs):\n",
    "        with redirect_stdout(NullIO()):\n",
    "            return fn(*args, **kwargs)\n",
    "    return silent_fn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ChoquetIntegral:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Instantiation of a ChoquetIntegral.\n",
    "           This sets up the ChI. It doesn't take any input parameters\n",
    "           because you may want to use pass your own values in(as opposed\n",
    "           to learning from data). To instatiate, use\n",
    "           chi = ChoquetIntegral.ChoquetIntegral()\n",
    "        \"\"\"\n",
    "        self.trainSamples, self.trainLabels = [], []\n",
    "        self.testSamples, self.testLabels = [], []\n",
    "        self.N, self.numberConstraints, self.M = 0, 0, 0\n",
    "        self.g = 0\n",
    "        self.fm = []\n",
    "        self.type = []\n",
    "\n",
    "\n",
    "    def train_chi(self, x1, l1):\n",
    "        \"\"\"\n",
    "        This trains this instance of your ChoquetIntegral w.r.t x1 and l1.\n",
    "        :param x1: These are the training samples of size N x M(inputs x number of samples)\n",
    "        :param l1: These are the training labels of size 1 x M(label per sample)\n",
    "        \"\"\"\n",
    "        self.type = 'quad'\n",
    "        self.trainSamples = x1\n",
    "        self.trainLabels = l1\n",
    "        self.N = self.trainSamples.shape[0]\n",
    "        self.M = self.trainSamples.shape[1]\n",
    "#         print(\"Number Inputs : \", self.N, \"; Number Samples : \", self.M)\n",
    "        self.fm = self.produce_lattice()\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "    def chi_quad(self, x2):\n",
    "        \"\"\"\n",
    "        This will produce an output for this instance of the ChI\n",
    "        This will use the learned(or specified) Choquet integral to\n",
    "        produce an output w.r.t. to the new input.\n",
    "        :param x2: testing sample\n",
    "        :return: output of the choquet integral.\n",
    "        \"\"\"\n",
    "        if self.type == 'quad':\n",
    "            n = len(x2)\n",
    "            pi_i = np.argsort(x2)[::-1][:n] + 1\n",
    "            ch = x2[pi_i[0] - 1] * (self.fm[str(pi_i[:1])])\n",
    "            for i in range(1, n):\n",
    "                latt_pti = np.sort(pi_i[:i + 1])\n",
    "                latt_ptimin1 = np.sort(pi_i[:i])\n",
    "                ch = ch + x2[pi_i[i] - 1] * (self.fm[str(latt_pti)] - self.fm[str(latt_ptimin1)])\n",
    "            return ch\n",
    "        else:\n",
    "            print(\"If using sugeno measure, you need to use chi_sugeno.\")\n",
    "\n",
    "\n",
    "    def produce_lattice(self):\n",
    "        \"\"\"\n",
    "            This method builds is where the lattice(or FM variables) will be learned.\n",
    "            The FM values can be found via a quadratic program, which is used here\n",
    "            after setting up constraint matrices. Refer to papers for complete overview.\n",
    "        :return: Lattice, the learned FM variables.\n",
    "        \"\"\"\n",
    "\n",
    "        fm_len = 2 ** self.N - 1  # nc\n",
    "        E = np.zeros((fm_len, fm_len))  # D\n",
    "        L = np.zeros(fm_len)  # f\n",
    "        index_keys = self.get_keys_index()\n",
    "        for i in range(0, self.M):  # it's going through one sample at a time.\n",
    "            l = self.trainLabels[i]  # this is the labels\n",
    "            fm_coeff = self.get_fm_class_img_coeff(index_keys, self.trainSamples[:, i], fm_len)  # this is Hdiff\n",
    "            # print(fm_coeff)\n",
    "            L = L + (-2) * l * fm_coeff\n",
    "            E = E + np.matmul(fm_coeff.reshape((fm_len, 1)), fm_coeff.reshape((1, fm_len)))\n",
    "\n",
    "        G, h, A, b = self.build_constraint_matrices(index_keys, fm_len)\n",
    "        solvers_qp = silent(solvers.qp)\n",
    "        sol = solvers_qp(matrix(2 * E, tc='d'), matrix(L.T, tc='d'), matrix(G, tc='d'), matrix(h, tc='d'),\n",
    "                         matrix(A, tc='d'), matrix(b, tc='d'))\n",
    "        g = sol['x']\n",
    "        Lattice = {}\n",
    "        for key in index_keys.keys():\n",
    "            Lattice[key] = g[index_keys[key]]\n",
    "        return Lattice\n",
    "\n",
    "\n",
    "    def build_constraint_matrices(self, index_keys, fm_len):\n",
    "        \"\"\"\n",
    "        This method builds the necessary constraint matrices.\n",
    "        :param index_keys: map to reference lattice components\n",
    "        :param fm_len: length of the fuzzy measure\n",
    "        :return: the constraint matrices\n",
    "        \"\"\"\n",
    "\n",
    "        vls = np.arange(1, self.N + 1)\n",
    "        line = np.zeros(fm_len)\n",
    "        G = line\n",
    "        line[index_keys[str(np.array([1]))]] = -1.\n",
    "        h = np.array([0])\n",
    "        for i in range(2, self.N + 1):\n",
    "            line = np.zeros(fm_len)\n",
    "            line[index_keys[str(np.array([i]))]] = -1.\n",
    "            G = np.vstack((G, line))\n",
    "            h = np.vstack((h, np.array([0])))\n",
    "        for i in range(2, self.N + 1):\n",
    "            parent = np.array(list(itertools.combinations(vls, i)))\n",
    "            for latt_pt in parent:\n",
    "                for j in range(len(latt_pt) - 1, len(latt_pt)):\n",
    "                    children = np.array(list(itertools.combinations(latt_pt, j)))\n",
    "                    for latt_ch in children:\n",
    "                        line = np.zeros(fm_len)\n",
    "                        line[index_keys[str(latt_ch)]] = 1.\n",
    "                        line[index_keys[str(latt_pt)]] = -1.\n",
    "                        G = np.vstack((G, line))\n",
    "                        h = np.vstack((h, np.array([0])))\n",
    "\n",
    "        line = np.zeros(fm_len)\n",
    "        line[index_keys[str(vls)]] = 1.\n",
    "        G = np.vstack((G, line))\n",
    "        h = np.vstack((h, np.array([1])))\n",
    "\n",
    "        # equality constraints\n",
    "        A = np.zeros((1, fm_len))\n",
    "        A[0, -1] = 1\n",
    "        b = np.array([1]);\n",
    "\n",
    "        return G, h, A, b\n",
    "\n",
    "\n",
    "    def get_fm_class_img_coeff(self, Lattice, h, fm_len):  # Lattice is FM_name_and_index, h is the samples, fm_len\n",
    "        \"\"\"\n",
    "        This creates a FM map with the name as the key and the index as the value\n",
    "        :param Lattice: dictionary with FM\n",
    "        :param h: sample\n",
    "        :param fm_len: fm length\n",
    "        :return: the fm_coeff\n",
    "        \"\"\"\n",
    "\n",
    "        n = len(h)  # len(h) is the number of the samples\n",
    "        fm_coeff = np.zeros(fm_len)\n",
    "        pi_i = np.argsort(h)[::-1][:n] + 1\n",
    "        for i in range(1, n):\n",
    "            fm_coeff[Lattice[str(np.sort(pi_i[:i]))]] = h[pi_i[i - 1] - 1] - h[pi_i[i] - 1]\n",
    "        fm_coeff[Lattice[str(np.sort(pi_i[:n]))]] = h[pi_i[n - 1] - 1]\n",
    "        np.matmul(fm_coeff, np.transpose(fm_coeff))\n",
    "        return fm_coeff\n",
    "\n",
    "\n",
    "    def get_keys_index(self):\n",
    "        \"\"\"\n",
    "        Sets up a dictionary for referencing FM.\n",
    "        :return: The keys to the dictionary\n",
    "        \"\"\"\n",
    "\n",
    "        vls = np.arange(1, self.N + 1)\n",
    "        count = 0\n",
    "        Lattice = {}\n",
    "        for i in range(0, self.N):\n",
    "            Lattice[str(np.array([vls[i]]))] = count\n",
    "            count = count + 1\n",
    "        for i in range(2, self.N + 1):\n",
    "            A = np.array(list(itertools.combinations(vls, i)))\n",
    "            for latt_pt in A:\n",
    "                Lattice[str(latt_pt)] = count\n",
    "                count = count + 1\n",
    "        return Lattice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066a2f3d",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/120 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data ready\n",
      "Train data superset size: (5, 6000)\n",
      "Test data ready\n",
      "Test data superset size: (5, 6000)\n",
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 50/120 [01:41<02:48,  2.41s/it]"
     ]
    }
   ],
   "source": [
    "# All in one\n",
    "\n",
    "\n",
    "# Creating data\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "dim = 5\n",
    "num_per_perm_train = 10\n",
    "num_per_perm_test = 10\n",
    "num_train = math.factorial(dim) * num_per_perm_train\n",
    "num_test = math.factorial(dim) * num_per_perm_test\n",
    "\n",
    "eva_func_num = 4\n",
    "\n",
    "# N! possible permutations\n",
    "all_perms = list(permutations(list(range(dim))))\n",
    "random.shuffle(all_perms)\n",
    "\n",
    "\n",
    "# Generate Train Data\n",
    "# Get a 5 times bigger superset to make sure each perm would have num_per_perm_train\n",
    "train_data_superset = np.random.rand(dim, num_train*5)\n",
    "train_data_perms = np.argsort(train_data_superset, 0)\n",
    "# train_data_by_perm = []\n",
    "train_data_superset_by_perm = []\n",
    "\n",
    "for i, current_perm in enumerate(all_perms):\n",
    "    temp = np.where(train_data_perms[0, :]==current_perm[0])\n",
    "    for j, idx in enumerate(current_perm):\n",
    "        temp = np.intersect1d(temp, np.where(train_data_perms[j, :]==idx))\n",
    "#         if temp.size == num_per_perm_train:\n",
    "#             break\n",
    "    if temp.size < num_per_perm_train:\n",
    "        print('Current permutation doesn\\'t have sufficient number of samples. Please regenerate!')\n",
    "        break\n",
    "    train_data_superset_by_perm.append(temp)\n",
    "print('Train data ready')\n",
    "print('Train data superset size:', train_data_superset.shape)\n",
    "    \n",
    "# Generate Test Data\n",
    "# Get a 5 times bigger superset to make sure each perm would have num_per_perm_test\n",
    "test_data_superset = np.random.rand(dim, num_test*5)\n",
    "test_data_perms = np.argsort(test_data_superset, 0)\n",
    "# test_data_by_perm = []\n",
    "test_data_superset_by_perm = []\n",
    "\n",
    "for i, current_perm in enumerate(all_perms):\n",
    "    temp = np.where(test_data_perms[0, :]==current_perm[0])\n",
    "    for j, idx in enumerate(current_perm):\n",
    "        temp = np.intersect1d(temp, np.where(test_data_perms[j, :]==idx))\n",
    "    if temp.size < num_per_perm_test:\n",
    "        print('Current permutation doesn\\'t have sufficient number of samples. Please regenerate!')\n",
    "        break\n",
    "    test_data_superset_by_perm.append(temp)\n",
    "print('Test data ready')\n",
    "print('Test data superset size:', test_data_superset.shape)\n",
    "\n",
    "    \n",
    "\n",
    "SSEs_all = np.zeros((len(all_perms), eva_func_num))\n",
    "SSEs_c_all = np.zeros((len(all_perms)-1, eva_func_num))\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    print('Epoch', epoch)\n",
    "#     train_data = np.random.rand(dim, num_train)\n",
    "#     train_data_perms = np.argsort(train_data, 0)\n",
    "    \n",
    "#     random.shuffle(all_perms)\n",
    "#     print(all_perms)\n",
    "\n",
    "    # Divide data into N! sets according to its permutation\n",
    "#     train_data_div_by_perm = []\n",
    "\n",
    "#     print('All permutations')\n",
    "#     for i, current_perm in enumerate(all_perms):\n",
    "# #         print(i, current_perm)\n",
    "#         temp = np.where(train_data_perms[0, :]==current_perm[0])\n",
    "#         for j, idx in enumerate(current_perm):\n",
    "#             temp = np.intersect1d(temp, np.where(train_data_perms[j, :]==idx))\n",
    "#         train_data_div_by_perm.append(temp)\n",
    "\n",
    "\n",
    "    # Test data\n",
    "    # Divide data into N! sets according to its permutation\n",
    "#     test_data_div_by_perm = []\n",
    "\n",
    "#     for i, current_perm in enumerate(all_perms):\n",
    "#         temp = np.where(test_data_perms[0, :]==current_perm[0])\n",
    "#         for j, idx in enumerate(current_perm):\n",
    "#             temp = np.intersect1d(temp, np.where(test_data_perms[j, :]==idx))\n",
    "#         test_data_div_by_perm.append(temp)\n",
    "        \n",
    "        \n",
    "    train_data_by_perm = []\n",
    "    test_data_by_perm = []\n",
    "    \n",
    "    for i, current_perm in enumerate(all_perms):\n",
    "        temp = train_data_superset_by_perm[i]\n",
    "        random.shuffle(temp)\n",
    "        train_data_by_perm.append(temp[0:num_per_perm_train])\n",
    "        \n",
    "        temp = test_data_superset_by_perm[i]\n",
    "        random.shuffle(temp)\n",
    "        test_data_by_perm.append(temp[0:num_per_perm_test])\n",
    "        \n",
    "    # Making N! train datasets with data percentage = i/N!\n",
    "    train_data_ioverN_percent = [train_data_by_perm[0]]\n",
    "    for i in range(1, len(all_perms)):\n",
    "        train_data_iN = np.concatenate((train_data_ioverN_percent[i-1], train_data_by_perm[i]))\n",
    "        random.shuffle(train_data_iN)\n",
    "        train_data_ioverN_percent.append(train_data_iN)\n",
    "\n",
    "#     print('train data size')\n",
    "#     for i, data_idx in enumerate(train_data_ioverN_percent):\n",
    "#         train_d = test_data_superset[:, data_idx]\n",
    "#         print(train_d.shape)\n",
    "\n",
    "\n",
    "    # Making N! test datasets with data percentage = i/N!\n",
    "    test_data_ioverN_percent = [test_data_by_perm[0]]\n",
    "    test_data_ioverN_percent_c = []\n",
    "    for i in range(1, len(all_perms)):\n",
    "        test_data_iN = np.concatenate((test_data_ioverN_percent[i-1], test_data_by_perm[i]))\n",
    "        test_data_iN_c = list(set(range(num_test)) - set(test_data_ioverN_percent[i-1]))\n",
    "        test_data_ioverN_percent.append(test_data_iN)\n",
    "        test_data_ioverN_percent_c.append(test_data_iN_c)\n",
    "\n",
    "#     print('test data size')\n",
    "#     for i, data_idx in enumerate(test_data_ioverN_percent):\n",
    "#         test_d = test_data[:, data_idx]\n",
    "#         print(test_d.shape)\n",
    "\n",
    "#     print('Test data complement size')\n",
    "#     for i, data_idx in enumerate(test_data_ioverN_percent_c):\n",
    "#         test_d_c = test_data[:, data_idx]\n",
    "#         print(test_d_c.shape)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    # Train\n",
    "\n",
    "#     eva_func_num = 4\n",
    "\n",
    "    SSEs = np.zeros((len(all_perms), eva_func_num))\n",
    "    SSEs_c = np.zeros((len(all_perms)-1, eva_func_num))\n",
    "\n",
    "    for i, data_idx in enumerate(tqdm(train_data_ioverN_percent)):\n",
    "#         print(i, 'i')\n",
    "#         print('Seen data percentage:', (i+1)/math.factorial(dim))\n",
    "\n",
    "        train_d = train_data_superset[:, data_idx]\n",
    "        test_d = test_data_superset[:, test_data_ioverN_percent[i]]\n",
    "\n",
    "        train_label_min = np.amin(train_d, 0)\n",
    "        train_label_max = np.amax(train_d, 0)\n",
    "        train_label_mean = np.mean(train_d, 0)\n",
    "        train_label_gmean = np.cbrt(np.prod(train_d, 0))\n",
    "\n",
    "        test_label_min = np.amin(test_d, 0)\n",
    "        test_label_max = np.amax(test_d, 0)\n",
    "        test_label_mean = np.mean(test_d, 0)\n",
    "        test_label_gmean = np.cbrt(np.prod(test_d, 0))\n",
    "\n",
    "        if i < len(all_perms)-1:\n",
    "            test_d_c = test_data_superset[:, test_data_ioverN_percent_c[i]]\n",
    "\n",
    "            test_label_min_c = np.amin(test_d_c, 0)\n",
    "            test_label_max_c = np.amax(test_d_c, 0)\n",
    "            test_label_mean_c = np.mean(test_d_c, 0)\n",
    "            test_label_gmean_c = np.cbrt(np.prod(test_d_c, 0))\n",
    "\n",
    "\n",
    "        chi = ChoquetIntegral()\n",
    "        chi.train_chi(train_d, train_label_min)\n",
    "        SSE = 0\n",
    "        for j in range(np.size(test_d, 1)):\n",
    "            chi_min_test = chi.chi_quad(test_d[:, j])\n",
    "            SSE += (chi_min_test - test_label_min[j]) ** 2\n",
    "        SSEs[i, 0] = SSE / np.size(test_d)\n",
    "#         print('\\nChi min', chi.fm)\n",
    "#         print('\\nSSE', SSE)\n",
    "        if i < len(all_perms)-1:\n",
    "            SSE_c = 0\n",
    "            for j in range(np.size(test_d_c, 1)):\n",
    "                chi_min_test_c = chi.chi_quad(test_d_c[:, j])\n",
    "                SSE_c += (chi_min_test_c - test_label_min_c[j]) ** 2\n",
    "            SSEs_c[i, 0] = SSE_c / np.size(test_d_c)\n",
    "#             print('\\nUnseen data SSE', SSE_c)\n",
    "\n",
    "\n",
    "        chi = ChoquetIntegral()\n",
    "        chi.train_chi(train_d, train_label_max)\n",
    "        SSE = 0\n",
    "        for j in range(np.size(test_d, 1)):\n",
    "            chi_max_test = chi.chi_quad(test_d[:, j])\n",
    "            SSE += (chi_max_test - test_label_max[j]) ** 2\n",
    "        SSEs[i, 1] = SSE / np.size(test_d)\n",
    "#         print('\\nChi max', chi.fm)\n",
    "#         print('\\nSSE', SSE)\n",
    "        if i < len(all_perms)-1:\n",
    "            SSE_c = 0\n",
    "            for j in range(np.size(test_d_c, 1)):\n",
    "                chi_max_test_c = chi.chi_quad(test_d_c[:, j])\n",
    "                SSE_c += (chi_max_test_c - test_label_max_c[j]) ** 2\n",
    "            SSEs_c[i, 1] = SSE_c / np.size(test_d_c)\n",
    "#             print('\\nUnseen data SSE', SSE_c)\n",
    "\n",
    "\n",
    "        chi = ChoquetIntegral()\n",
    "        chi.train_chi(train_d, train_label_mean)\n",
    "        SSE = 0\n",
    "        for j in range(np.size(test_d, 1)):\n",
    "            chi_mean_test = chi.chi_quad(test_d[:, j])\n",
    "            SSE += (chi_mean_test - test_label_mean[j]) ** 2\n",
    "        SSEs[i, 2] = SSE / np.size(test_d)\n",
    "#         print('\\nChi mean', chi.fm)\n",
    "#         print('\\nSSE', SSE)\n",
    "        if i < len(all_perms)-1:\n",
    "            SSE_c = 0\n",
    "            for j in range(np.size(test_d_c, 1)):\n",
    "                chi_mean_test_c = chi.chi_quad(test_d_c[:, j])\n",
    "                SSE_c += (chi_mean_test_c - test_label_mean_c[j]) ** 2\n",
    "            SSEs_c[i, 2] = SSE_c / np.size(test_d_c)\n",
    "#             print('\\nUnseen data SSE', SSE_c)\n",
    "\n",
    "\n",
    "        chi = ChoquetIntegral()\n",
    "        chi.train_chi(train_d, train_label_gmean)\n",
    "        SSE = 0\n",
    "        for j in range(np.size(test_d, 1)):\n",
    "            chi_gmean_test = chi.chi_quad(test_d[:, j])\n",
    "            SSE += (chi_gmean_test - test_label_gmean[j]) ** 2\n",
    "        SSEs[i, 3] = SSE / np.size(test_d)\n",
    "#         print('\\nChi geometric mean', chi.fm)\n",
    "#         print('\\nSSE', SSE)\n",
    "        if i < len(all_perms)-1:\n",
    "            SSE_c = 0\n",
    "            for j in range(np.size(test_d_c, 1)):\n",
    "                chi_gmean_test_c = chi.chi_quad(test_d_c[:, j])\n",
    "                SSE_c += (chi_gmean_test_c - test_label_gmean_c[j]) ** 2\n",
    "            SSEs_c[i, 3] = SSE_c / np.size(test_d_c)\n",
    "#             print('\\nUnseen data SSE', SSE_c)\n",
    "\n",
    "\n",
    "#         print('\\n\\n\\n')\n",
    "        \n",
    "        SSEs_all += SSEs\n",
    "        SSEs_c_all += SSEs_c\n",
    "        \n",
    "        \n",
    "SSEs_avg = SSEs_all / num_epoch\n",
    "SSEs_c_avg = SSEs_c_all / num_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9296723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24,) (24, 4)\n",
      "[0.04166667 0.08333333 0.125      0.16666667 0.20833333 0.25\n",
      " 0.29166667 0.33333333 0.375      0.41666667 0.45833333 0.5\n",
      " 0.54166667 0.58333333 0.625      0.66666667 0.70833333 0.75\n",
      " 0.79166667 0.83333333 0.875      0.91666667 0.95833333 1.        ]\n",
      "[[1.72256182e-07 2.52120414e-07 1.75379035e-13 8.13767658e-03]\n",
      " [1.61810165e-07 3.35168000e-07 1.55012595e-10 7.58326466e-03]\n",
      " [1.07228199e-07 3.99371183e-07 1.30722644e-10 1.08291327e-02]\n",
      " [9.17165710e-08 4.59542377e-07 7.19617171e-10 9.41829009e-03]\n",
      " [7.95029652e-08 1.02255065e-06 1.54610808e-12 8.25478317e-03]\n",
      " [7.04562840e-08 1.00003912e-06 3.57301794e-12 8.36678800e-03]\n",
      " [5.67735073e-08 8.29527859e-07 5.85720131e-12 7.23061358e-03]\n",
      " [9.08447339e-08 7.38918724e-07 7.69687490e-12 7.15036539e-03]\n",
      " [1.30423108e-07 6.37696225e-07 1.70751582e-11 6.28244065e-03]\n",
      " [1.06124844e-07 4.93847514e-07 3.08682102e-12 5.99985349e-03]\n",
      " [8.66470602e-08 4.15525607e-07 2.26244674e-11 5.33347284e-03]\n",
      " [7.12319789e-08 3.65991452e-07 2.87756947e-12 4.71221132e-03]\n",
      " [5.89693592e-08 3.10259554e-07 1.46729266e-12 4.35274071e-03]\n",
      " [4.51999963e-08 2.71964568e-07 7.45589405e-15 3.93056163e-03]\n",
      " [3.80065262e-08 2.21575526e-07 5.09766137e-15 3.52756026e-03]\n",
      " [3.07364442e-08 1.82436263e-07 4.85604244e-15 3.16079890e-03]\n",
      " [2.51560039e-08 1.49397459e-07 5.73660029e-13 2.77082312e-03]\n",
      " [2.07133470e-08 1.23669455e-07 3.61841528e-13 2.38966289e-03]\n",
      " [1.56744730e-08 9.74559073e-08 8.15881099e-13 1.98779154e-03]\n",
      " [1.21645395e-08 7.48433715e-08 1.44933837e-12 1.68080414e-03]\n",
      " [8.84026403e-09 5.76494434e-08 1.14555618e-12 1.35197471e-03]\n",
      " [6.37990990e-09 6.03320206e-08 6.17333393e-13 9.97695775e-04]\n",
      " [3.92281267e-09 1.22041559e-07 4.88608573e-13 6.71635404e-04]\n",
      " [1.85247041e-09 7.90589104e-08 1.90995929e-13 3.35128750e-04]]\n",
      "(23,) (23, 4)\n",
      "[0.04166667 0.08333333 0.125      0.16666667 0.20833333 0.25\n",
      " 0.29166667 0.33333333 0.375      0.41666667 0.45833333 0.5\n",
      " 0.54166667 0.58333333 0.625      0.66666667 0.70833333 0.75\n",
      " 0.79166667 0.83333333 0.875      0.91666667 0.95833333]\n",
      "[[3.71623437e-01 3.61631334e-01 1.53801464e-02 1.57288674e-01]\n",
      " [1.87238693e-01 1.56271505e-01 1.31862070e-02 8.14424289e-02]\n",
      " [1.79168020e-01 3.71745229e-02 9.48811334e-03 7.92976673e-02]\n",
      " [5.17750755e-02 3.42886491e-02 5.18824933e-03 2.89523138e-02]\n",
      " [8.35466674e-08 3.19311143e-02 1.94785500e-03 9.07671794e-03]\n",
      " [7.26946179e-08 1.15487701e-06 2.62071249e-06 8.26943706e-03]\n",
      " [6.64666346e-08 9.56541358e-07 2.88799702e-06 7.72531830e-03]\n",
      " [1.19866658e-07 8.05391933e-07 9.90903035e-06 7.14645524e-03]\n",
      " [1.88012836e-07 6.57841198e-07 2.83400573e-11 6.72341612e-03]\n",
      " [1.31464447e-07 5.24674529e-07 7.79202368e-12 6.13496090e-03]\n",
      " [1.16149003e-07 4.64499398e-07 7.60583888e-11 5.72231515e-03]\n",
      " [9.39376710e-08 3.58374586e-07 5.79660782e-12 4.81262410e-03]\n",
      " [8.05475842e-08 2.96567691e-07 4.31860569e-12 4.34971317e-03]\n",
      " [5.13846796e-08 2.49386505e-07 1.12684979e-14 3.79081873e-03]\n",
      " [4.31890834e-08 2.00011943e-07 7.48535297e-15 3.43474699e-03]\n",
      " [3.63984465e-08 1.65287861e-07 7.95001640e-15 3.09942167e-03]\n",
      " [3.07521420e-08 1.36669712e-07 4.80108304e-13 2.72042071e-03]\n",
      " [2.55030105e-08 1.14628754e-07 2.93488472e-13 2.37378538e-03]\n",
      " [1.69428079e-08 8.91595318e-08 6.53166391e-13 1.97204178e-03]\n",
      " [1.36761686e-08 6.98919663e-08 1.41609660e-12 1.62088040e-03]\n",
      " [8.79598256e-09 5.39178075e-08 1.04558274e-12 1.26247596e-03]\n",
      " [6.34433924e-09 5.54776185e-08 5.60165391e-13 9.48878025e-04]\n",
      " [3.80458870e-09 1.11107447e-07 4.86701250e-13 6.32061035e-04]]\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x = (np.asarray(list(range(1, len(all_perms)+1)))) / len(all_perms)\n",
    "print(x.shape, SSEs_avg.shape)\n",
    "print(x)\n",
    "print(SSEs_avg)\n",
    "plt.plot(x, SSEs_avg)\n",
    "ax.set_title('SSE (Data with same pattern)')\n",
    "ax.legend(['Min', 'Max', 'Mean', 'Geometric Mean'])\n",
    "ax.set_xlabel('Percentage of Seen Data')\n",
    "ax.set_ylabel('SSEs avg')\n",
    "ax.xaxis.set_major_formatter(FuncFormatter('{0:.0%}'.format))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = (np.asarray(list(range(1, len(all_perms))))) / len(all_perms)\n",
    "print(x.shape, SSEs_c_avg.shape)\n",
    "print(x)\n",
    "print(SSEs_c_avg)\n",
    "plt.plot(x, SSEs_c_avg)\n",
    "ax.set_title('SSE (Data with unseen pattern)')\n",
    "ax.legend(['Min', 'Max', 'Mean', 'Geometric Mean'])\n",
    "ax.set_xlabel('Percentage of Seen Data')\n",
    "ax.set_ylabel('SSEs avg')\n",
    "ax.xaxis.set_major_formatter(FuncFormatter('{0:.0%}'.format))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc65055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f54063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
