{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3483bec",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macOS\n",
      "Interactive plot activated\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "# import itertools\n",
    "from itertools import permutations\n",
    "import math\n",
    "# import os\n",
    "import pickle\n",
    "import platform\n",
    "import random\n",
    "from tkinter import Tk\n",
    "\n",
    "# from cvxopt import solvers, matrix\n",
    "from matplotlib import animation\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import numpy as np\n",
    "import torch\n",
    "# import torchvision\n",
    "# from torchvision import transforms, models,datasets\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from tools import *\n",
    "import tools\n",
    "\n",
    "# Extend width of Jupyter Notebook Cell to the size of browser\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# OS related settings\n",
    "if platform.system() == 'Windows':\n",
    "    print('Windows')\n",
    "#     %matplotlib tk\n",
    "    %matplotlib qt\n",
    "elif platform.system() == 'Darwin':\n",
    "    print('macOS')\n",
    "    Tk().withdraw()\n",
    "    %matplotlib osx\n",
    "elif platform == 'linux' or platform == 'linux2':\n",
    "    print('Linux')\n",
    "# This line of \"print\" must exist right after %matplotlib command, otherwise JN will hang on the first import statement after this.\n",
    "print('Interactive plot activated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8d9cd83",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_repetition = 4\n",
    "\n",
    "dim_list = list(range(4, 5))\n",
    "\n",
    "# num_per_perm_list_train = [30]\n",
    "# num_per_perm_list_train = [1, 10]\n",
    "num_per_perm_list_train = [1, 10, 50, 100] # Every permutation gets the same number of train/test data samples\n",
    "num_per_perm_list_test = [10] # Every permutation gets the same number of train/test data samples\n",
    "\n",
    "superset_factor = 4 # Create a superset # times larger than what is needed to ensure each class would have sufficient number of samples\n",
    "\n",
    "distributions = ['uniform', 'normal', 'bimodal']\n",
    "distribution = distributions[0]\n",
    "\n",
    "weights = {3: np.asarray([[0.8, 0.1, 0.1],\n",
    "                          [0.2, 0.7, 0.1],\n",
    "                          [0.5, 0.2, 0.3],\n",
    "                          [0.1, 0.3, 0.5]]),\n",
    "           4: np.asarray([[0.1, 0.2, 0.3, 0.4],\n",
    "                          [0.2, 0.2, 0.2, 0.4],\n",
    "                          [0, 0.1, 0.3, 0.6],\n",
    "                          [0, 0, 0.4, 0.6]]),\n",
    "           5: np.asarray([[0.1, 0.1, 0.1, 0.2, 0.5],\n",
    "                          [0, 0, 0.4, 0.3, 0.3],\n",
    "                          [0, 0, 0, 0.4, 0.6],\n",
    "                          [0.1, 0.8, 0.1, 0, 0]]),\n",
    "           6: np.asarray([[0.1, 0.1, 0.1, 0.1, 0.2, 0.4],\n",
    "                          [0, 0, 0.3, 0.3, 0.3, 0.1],\n",
    "                          [0, 0, 0, 0, 0.4, 0.6],\n",
    "                          [0.1, 0.7, 0.1, 0.1, 0, 0]]),}\n",
    "\n",
    "avg_funcs = [np.amin, np.amax, np.mean, None, None, None, None] # List of avg functions\n",
    "\n",
    "avg_names = {}\n",
    "for dim in dim_list:\n",
    "    weight = weights[dim]\n",
    "    weight_legend = []\n",
    "    for w in weight:\n",
    "        weight_legend.append(' '.join(map(str, (w*10).astype(int))))\n",
    "    avg_names[dim] = ['Min', 'Max', 'Mean'] + weight_legend\n",
    "\n",
    "train_group_num_limit = math.factorial(4)\n",
    "\n",
    "models = [tools.Choquet_Integral_QP]\n",
    "model_names = ['QP']\n",
    "\n",
    "# models = [tools.Choquet_Integral_NN]\n",
    "# model_names = ['NN']\n",
    "\n",
    "# models = [tools.Choquet_Integral_QP, tools.Choquet_Integral_NN]\n",
    "# model_names = ['QP', 'NN']\n",
    "\n",
    "# models = [tools.Choquet_Integral_QP, tools.Choquet_Integral_QP]\n",
    "# model_names = ['QP', 'QP']\n",
    "\n",
    "\n",
    "output_dir = 'output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63423c67",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Time1:  0.027438848999736365\n",
      "Time2:  0.0052636799996435\n",
      "[(0, 2, 3, 1), (0, 3, 2, 1), (3, 0, 1, 2), (2, 3, 1, 0), (3, 1, 2, 0), (2, 0, 3, 1), (1, 0, 3, 2), (3, 0, 2, 1), (0, 2, 1, 3), (1, 2, 3, 0), (3, 2, 0, 1), (2, 1, 3, 0), (3, 1, 0, 2), (2, 1, 0, 3), (2, 0, 1, 3), (0, 1, 2, 3), (1, 2, 0, 3), (2, 3, 0, 1), (3, 2, 1, 0), (0, 3, 1, 2), (1, 3, 2, 0), (0, 1, 3, 2), (1, 3, 0, 2), (1, 0, 2, 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:11<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time3:  11.404983904000346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:14<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time3:  14.709979129999738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:28<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time3:  28.729531786999814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:46<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time3:  46.73658417600018\n",
      "Time1:  0.031178232000002026\n",
      "Time2:  0.00798924100035947\n",
      "[(1, 0, 3, 2), (3, 2, 1, 0), (3, 1, 0, 2), (0, 3, 2, 1), (1, 2, 3, 0), (1, 3, 2, 0), (2, 3, 1, 0), (0, 2, 1, 3), (3, 0, 2, 1), (2, 1, 0, 3), (0, 2, 3, 1), (0, 1, 3, 2), (3, 0, 1, 2), (2, 1, 3, 0), (1, 3, 0, 2), (2, 0, 3, 1), (1, 2, 0, 3), (3, 2, 0, 1), (1, 0, 2, 3), (2, 0, 1, 3), (0, 1, 2, 3), (3, 1, 2, 0), (0, 3, 1, 2), (2, 3, 0, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:11<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time3:  11.439905048999663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:14<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time3:  14.753950091000206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:29<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time3:  29.499657662000118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:47<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time3:  47.69563684500008\n",
      "Time1:  0.027349556000444863\n",
      "Time2:  0.006587851000404044\n",
      "[(1, 3, 2, 0), (0, 1, 3, 2), (2, 3, 1, 0), (0, 2, 1, 3), (3, 2, 0, 1), (0, 3, 1, 2), (2, 0, 1, 3), (1, 0, 3, 2), (1, 3, 0, 2), (2, 3, 0, 1), (1, 2, 0, 3), (0, 3, 2, 1), (1, 0, 2, 3), (3, 1, 0, 2), (0, 2, 3, 1), (3, 1, 2, 0), (1, 2, 3, 0), (3, 0, 1, 2), (3, 0, 2, 1), (2, 1, 3, 0), (2, 0, 3, 1), (2, 1, 0, 3), (3, 2, 1, 0), (0, 1, 2, 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:12<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time3:  12.724144230999627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:14<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time3:  14.768873251000514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:34<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time3:  34.1814068599997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:11<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time3:  71.83723691799969\n",
      "Time1:  0.04996182300055807\n",
      "Time2:  0.008065947000432061\n",
      "[(1, 2, 3, 0), (0, 1, 3, 2), (3, 0, 2, 1), (0, 3, 1, 2), (0, 3, 2, 1), (2, 0, 3, 1), (2, 1, 0, 3), (2, 3, 0, 1), (1, 2, 0, 3), (0, 2, 3, 1), (2, 1, 3, 0), (3, 2, 1, 0), (3, 1, 0, 2), (3, 1, 2, 0), (3, 2, 0, 1), (0, 2, 1, 3), (1, 3, 2, 0), (3, 0, 1, 2), (2, 0, 1, 3), (0, 1, 2, 3), (1, 0, 3, 2), (1, 0, 2, 3), (2, 3, 1, 0), (1, 3, 0, 2)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:19<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time3:  19.50635001000046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:16<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time3:  16.032608617999358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:30<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time3:  30.98674755799948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:48<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time3:  48.13338347700028\n",
      "Time0:  453.3122175319995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "import timeit\n",
    "start0 = timeit.default_timer()\n",
    "num_tqdm = num_repetition*len(dim_list)*len(num_per_perm_list_train)\n",
    "print(num_tqdm)\n",
    "\n",
    "# [Dim, Rep, #perPerm, % of perm, avg_func, model]\n",
    "MSEs_seen_by_dim = {}\n",
    "MSEs_unseen_by_dim = {}\n",
    "FM_by_dim = {}\n",
    "\n",
    "\n",
    "\n",
    "for rep in range(num_repetition):\n",
    "    start1 = timeit.default_timer()\n",
    "    train_data_source = tools.Data_Source(dim_list[-1], num_per_perm_list_train[-1], superset_factor, distribution)\n",
    "    stop1 = timeit.default_timer()\n",
    "    print('Time1: ', stop1 - start1)   \n",
    "    train_superset = train_data_source.get_superset()\n",
    "    \n",
    "    start2 = timeit.default_timer()\n",
    "    test_data_source = tools.Data_Source(dim_list[-1], num_per_perm_list_test[-1], superset_factor, distribution)\n",
    "    stop2 = timeit.default_timer()\n",
    "    print('Time2: ', stop2 - start2)   \n",
    "    test_superset = test_data_source.get_superset()\n",
    "    \n",
    "    random_seed = random.random()\n",
    "    \n",
    "    for dim in dim_list:\n",
    "\n",
    "        for avg_idx in range(len(weights[dim])):\n",
    "            avg_funcs[3+avg_idx] = tools.w_avg(weights[dim][avg_idx])\n",
    "\n",
    "        all_perms = list(permutations(list(range(dim)))) # N! possible permutations\n",
    "#         random.Random(rep*random_seed).shuffle(all_perms)\n",
    "        random.shuffle(all_perms)\n",
    "        print(all_perms)\n",
    "        \n",
    "        # When the # of possible permutations exceed certain number (in here 5!), \n",
    "        # instead of feeding only one more permutation a time, feed more.\n",
    "        if len(all_perms) > train_group_num_limit:\n",
    "            step = int(len(all_perms) / train_group_num_limit)\n",
    "        else:\n",
    "            step = 1\n",
    "\n",
    "        # Mean Squared Error [for each repetition, for each avg function, for each model, for each percentage, for each data#perperm, for each dim], of all test samples, for both seen and unseen data.\n",
    "        MSEs_seen = np.zeros((len(num_per_perm_list_train), len(range(step-1, len(all_perms), step)), len(avg_funcs), len(models)))\n",
    "        MSEs_unseen = np.zeros((len(num_per_perm_list_train), len(range(step-1, len(all_perms), step))-1, len(avg_funcs), len(models)))\n",
    "        # Record FM after train session with both seen and unseen data pattern\n",
    "        FM = np.zeros((len(num_per_perm_list_train), len(range(step-1, len(all_perms), step)), len(avg_funcs), len(models), 2**dim-1))\n",
    "\n",
    "    \n",
    "        for npp_idx, num_per_perm in enumerate(num_per_perm_list_train):\n",
    "            \n",
    "            train_idx_by_perm = train_data_source.get_data_idx(dim, num_per_perm)\n",
    "            test_idx_by_perm = test_data_source.get_data_idx(dim, num_per_perm_list_test[0])\n",
    "            start3 = timeit.default_timer()\n",
    "            for perc_idx, perc in enumerate(tqdm(range(step-1, len(all_perms), step))):\n",
    "                \n",
    "#             for perc_idx, perc in enumerate(range(step-1, len(all_perms), step)):\n",
    "                # Find index of train/test sample in superset and shuffle\n",
    "                train_idx = np.concatenate(train_idx_by_perm[0:perc+1])\n",
    "                np.random.shuffle(train_idx)\n",
    "                test_idx = np.concatenate(test_idx_by_perm[0:perc+1])\n",
    "                # Find data sample through index\n",
    "                train_d = train_superset[:, train_idx][0:dim]\n",
    "                test_d = test_superset[:, test_idx][0:dim]\n",
    "                # Define unseen test data samples when the train data doesn't cover 100% of the permutation\n",
    "                if perc < len(all_perms)-1:\n",
    "                    test_idx_unseen = np.concatenate(test_idx_by_perm[perc+1:])\n",
    "                    test_d_unseen = test_superset[:, test_idx_unseen][0:dim]\n",
    "                else:\n",
    "                    test_d_unseen = []\n",
    "\n",
    "                # Define subsets of 'X', or keys for fuzzy measure. Like '1 2' or '1 3 4 5' for g(x1, x2) or g(x1, x3, x4, x5)\n",
    "                sourcesInNode, subset = tools.sources_and_subsets_nodes(dim)\n",
    "                keys = [str(np.sort(i)+1) for i in sourcesInNode]\n",
    "                \n",
    "                for avg_idx, avg_func in enumerate(avg_funcs):\n",
    "                    start4 = timeit.default_timer()\n",
    "                    # Calculate label with given avg function\n",
    "                    train_label = avg_func(train_d, 0)\n",
    "                    test_label = avg_func(test_d, 0)\n",
    "                    \n",
    "                    for model_idx, model in enumerate(models):\n",
    "                        start5 = timeit.default_timer()\n",
    "                        if model_names[model_idx] == 'QP':\n",
    "                            # Initialize ChIQP\n",
    "                            chi_model = model()\n",
    "                            # Train \n",
    "                            chi_model.train_chi(train_d, train_label)\n",
    "                            # Get fuzzy measure learned\n",
    "                            fm = chi_model.fm\n",
    "                            \n",
    "                        elif model_names[model_idx] == 'NN':\n",
    "                            # Initialize ChINN\n",
    "                            chi_model = model(dim, 1)\n",
    "                            # Parameters for training NN\n",
    "                            lr = 0.05 # Learning rate\n",
    "                            num_epoch = 100\n",
    "                            criterion = torch.nn.MSELoss(reduction='mean')\n",
    "                            optimizer = torch.optim.SGD(chi_model.parameters(), lr=lr)\n",
    "                            \n",
    "                            # Train \n",
    "                            tools.train_chinn(chi_model, lr, criterion, optimizer, num_epoch, torch.tensor(train_d, dtype=torch.float), torch.tensor(train_label, dtype=torch.float))\n",
    "                            # Get fuzzy measure learned\n",
    "                            FM_learned = (chi_model.chi_nn_vars(chi_model.vars).cpu()).detach().numpy()\n",
    "                            fm_dict_binary = dict(zip(keys, FM_learned[:,0]))\n",
    "                            fm_dict_lexicographic = tools.get_keys_index(dim)\n",
    "                            for key in fm_dict_lexicographic.keys():\n",
    "                                fm_dict_lexicographic[key] = fm_dict_binary[key]\n",
    "                            fm = fm_dict_lexicographic\n",
    "                            \n",
    "                        stop5 = timeit.default_timer()\n",
    "#                         print('Time5: ', stop5 - start5)\n",
    "                        \n",
    "                        FM[npp_idx, perc_idx, avg_idx, model_idx, :] = np.asarray(list(fm.values()))\n",
    "                        # Calculate result from integral with test data\n",
    "                        test_output = np.apply_along_axis(tools.get_cal_chi(fm), 0, test_d)\n",
    "                        MSE = ((test_output - test_label)**2).mean()\n",
    "                        MSEs_seen[npp_idx, perc_idx, avg_idx, model_idx] = MSE\n",
    "                        # Calculate result from integral with test data - unseen\n",
    "                        if perc < len(all_perms)-1:\n",
    "                            test_label_unseen = avg_func(test_d_unseen, 0)\n",
    "                            test_out_unseen = np.apply_along_axis(tools.get_cal_chi(fm), 0, test_d_unseen)\n",
    "                            MSEs_unseen[npp_idx, perc_idx, avg_idx, model_idx] = ((test_out_unseen - test_label_unseen)**2).mean()\n",
    "                    stop4 = timeit.default_timer()\n",
    "#                     print('Time4: ', stop4 - start4)\n",
    "#                     print('Time5/4: ', (stop5-start5)/(stop4-start4))\n",
    "            stop3 = timeit.default_timer()\n",
    "            print('Time3: ', stop3 - start3)  \n",
    "        if dim in FM_by_dim.keys():\n",
    "            FM_by_dim[dim] = np.append(FM_by_dim[dim], np.expand_dims(FM, axis=0), axis=0)\n",
    "            MSEs_seen_by_dim[dim] = np.append(MSEs_seen_by_dim[dim], np.expand_dims(MSEs_seen, axis=0), axis=0)\n",
    "            MSEs_unseen_by_dim[dim] = np.append(MSEs_unseen_by_dim[dim], np.expand_dims(MSEs_unseen, axis=0), axis=0)\n",
    "        else:\n",
    "            FM_by_dim[dim] = np.expand_dims(FM, axis=0)\n",
    "            MSEs_seen_by_dim[dim] = np.expand_dims(MSEs_seen, axis=0)\n",
    "            MSEs_unseen_by_dim[dim] = np.expand_dims(MSEs_unseen, axis=0)\n",
    "\n",
    "    \n",
    "stop0 = timeit.default_timer()\n",
    "print('Time0: ', stop0 - start0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a540b0b6",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "now = datetime.datetime.now().strftime(\"-%m-%d-%Y@%H.%M.%S\")\n",
    "with open(output_dir + 'ChI_saved_file' + now, 'wb') as f:\n",
    "    pickle.dump(FM_by_dim, f)\n",
    "    pickle.dump(MSEs_seen_by_dim, f)\n",
    "    pickle.dump(MSEs_unseen_by_dim, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5e3f22a4",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.close('all')\n",
    "# Plot for seen\n",
    "for dim in dim_list:\n",
    "    MSEs_seen = MSEs_seen_by_dim[dim]\n",
    "    MSE_mean = np.mean(MSEs_seen, 0)\n",
    "    MSE_max = np.max(MSEs_seen, 0)\n",
    "    MSE_min = np.min(MSEs_seen, 0)\n",
    "    \n",
    "    num_perm = math.factorial(dim)\n",
    "    \n",
    "    for npp_idx in range(len(num_per_perm_list_train)):\n",
    "        for model_idx in range(len(model_names)):\n",
    "            fig, ax = plt.subplots()\n",
    "            x = (np.arange(MSE_mean.shape[1])+1) / MSE_mean.shape[1]\n",
    "            plt.plot(x, MSE_mean[npp_idx, :, :, model_idx])\n",
    "            ax.set_title('MSE (seen), Model=' + model_names[model_idx] + ', Dim=' + str(dim) + ', NPP=' + str(num_per_perm_list_train[npp_idx]))\n",
    "            \n",
    "            ax.legend(avg_names[dim])\n",
    "            \n",
    "            ax.set_xlabel('Percentage of Seen Data')\n",
    "            ax.set_ylabel('MSEs avg')\n",
    "            ax.xaxis.set_major_formatter(FuncFormatter('{0:.0%}'.format))\n",
    "\n",
    "            for avg_idx in range(len(avg_funcs)):\n",
    "                plt.fill_between(x, MSE_min[npp_idx, :, avg_idx, model_idx], MSE_max[npp_idx, :, avg_idx, model_idx], alpha=0.1)\n",
    "                \n",
    "            plt.savefig(output_dir + model_names[model_idx] + ' Dim=' + str(dim) + ' NPP=' + str(num_per_perm_list_train[npp_idx]) + ' (MSE seen).png')\n",
    "                \n",
    "                \n",
    "# Plot for unseen\n",
    "for dim in dim_list:\n",
    "    MSEs_unseen = MSEs_unseen_by_dim[dim]\n",
    "    MSE_mean = np.mean(MSEs_unseen, 0)\n",
    "    MSE_max = np.max(MSEs_unseen, 0)\n",
    "    MSE_min = np.min(MSEs_unseen, 0)\n",
    "    \n",
    "    num_perm = math.factorial(dim)\n",
    "\n",
    "    for npp_idx in range(MSE_mean.shape[0]):\n",
    "        for model_idx in range(MSE_mean.shape[-1]):\n",
    "            fig, ax = plt.subplots()\n",
    "            x = (np.arange(MSE_mean.shape[1])+1) / (MSE_mean.shape[1]+1)\n",
    "            plt.plot(x, MSE_mean[npp_idx, :, :, model_idx])\n",
    "            ax.set_title('MSE (unseen), Model=' + model_names[model_idx] + ', Dim=' + str(dim) + ', NPP=' + str(num_per_perm_list_train[npp_idx]))\n",
    "            \n",
    "            ax.legend(avg_names[dim])\n",
    "            \n",
    "            ax.set_xlabel('Percentage of Seen Data')\n",
    "            ax.set_ylabel('MSEs avg')\n",
    "            ax.xaxis.set_major_formatter(FuncFormatter('{0:.0%}'.format))\n",
    "\n",
    "            for avg_idx in range(len(avg_funcs)):\n",
    "                plt.fill_between(x, MSE_min[npp_idx, :, avg_idx, model_idx], MSE_max[npp_idx, :, avg_idx, model_idx], alpha=0.1)\n",
    "                \n",
    "            plt.savefig(output_dir + model_names[model_idx] + ' Dim=' + str(dim) + ' NPP=' + str(num_per_perm_list_train[npp_idx]) + ' (MSE unseen).png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9e949c21",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Video for FM change\n",
    "\n",
    "\n",
    "\n",
    "for dim in dim_list:\n",
    "    FM = FM_by_dim[dim]\n",
    "    FM_mean = np.mean(FM, 0)\n",
    "    FM_min = np.amin(FM, 0)\n",
    "    FM_max = np.amax(FM, 0)\n",
    "    \n",
    "    avg_name = avg_names[dim]\n",
    "    fm_targets = [tools.get_min_fm_target, tools.get_max_fm_target, tools.get_mean_fm_target, tools.get_w_avg_target(weights[dim][0]), tools.get_w_avg_target(weights[dim][1]), tools.get_w_avg_target(weights[dim][2]), tools.get_w_avg_target(weights[dim][3])]\n",
    "    \n",
    "    \n",
    "    for npp_idx in range(len(num_per_perm_list_train)):\n",
    "        for model_idx in range(len(model_names)):\n",
    "            for avg_idx, fm_target in enumerate(fm_targets):\n",
    "                fm_mean = FM_mean[npp_idx, :, avg_idx, model_idx, :]\n",
    "                fm_min = FM_min[npp_idx, :, avg_idx, model_idx, :]\n",
    "                fm_max = FM_max[npp_idx, :, avg_idx, model_idx, :]\n",
    "\n",
    "                # First set up the figure, the axis, and the plot element we want to animate\n",
    "                fig = plt.figure()\n",
    "                ax = plt.axes(xlim=(0, np.size(fm_mean, -1)-1), ylim=(-0.1, 1.1))\n",
    "                line, = ax.plot([], [], lw=2)\n",
    "                ax.set_xlabel('Fuzzy Measure Key')\n",
    "                ax.set_ylabel('Fuzzy Measure Value')\n",
    "                ax.set_title(model_names[model_idx] + ', Dim=' + str(dim) + ', NPP=' + str(num_per_perm_list_train[npp_idx]) + ' ' + avg_name[avg_idx])\n",
    "\n",
    "                # initialization function: plot the background of each frame\n",
    "                def init():\n",
    "                    x = list(range(np.size(fm_mean, -1)))\n",
    "                    y = list(fm_target(dim).values())\n",
    "                    plt.plot(x, y)\n",
    "                    ax.legend(['FM Target'], loc=4)\n",
    "\n",
    "\n",
    "                # animation function.  This is called sequentially\n",
    "                def animate(i):\n",
    "                    x = np.asarray(list(range(np.size(fm_mean, -1))))\n",
    "                    y = fm_mean[i, :]\n",
    "                    line.set_data(x, y)\n",
    "                    ax.legend(['FM Predict (Seen data percentage ' + str(\"{0:.0%}\".format((i+1)/np.size(fm_mean, 0))) + ')', 'FM Target'])\n",
    "                    ax.collections = []\n",
    "                    plt.fill_between(x, fm_min[i, :], fm_max[i, :], color='blue', alpha=0.1)\n",
    "                    return line,\n",
    "\n",
    "                # call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "                anim = animation.FuncAnimation(fig, animate, frames=np.size(fm_mean, 0), init_func=init(), interval=200, blit=True)\n",
    "\n",
    "                # save the animation as an mp4.  This requires ffmpeg or mencoder to be\n",
    "                # installed.  The extra_args ensure that the x264 codec is used, so that\n",
    "                # the video can be embedded in html5.  You may need to adjust this for\n",
    "                # your system: for more information, see\n",
    "                # http://matplotlib.sourceforge.net/api/animation_api.html\n",
    "                anim.save(output_dir + model_names[model_idx] + ', Dim=' + str(dim) + ', NPP=' + str(num_per_perm_list_train[npp_idx]) + ' w_AVG=' + avg_name[avg_idx] + '.mp4', fps=3)\n",
    "        #         plt.show()\n",
    "                plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ad152fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
