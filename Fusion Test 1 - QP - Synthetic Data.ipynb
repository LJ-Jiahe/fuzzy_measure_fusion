{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba2dffb",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macOS\n",
      "Interactive plot activated\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "from itertools import permutations, combinations\n",
    "import os\n",
    "import pickle\n",
    "import platform\n",
    "import random\n",
    "from tkinter import Tk\n",
    "\n",
    "from cvxopt import solvers, matrix\n",
    "import math\n",
    "from matplotlib import animation\n",
    "from  matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, models,datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Extend width of Jupyter Notebook Cell to the size of browser\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# OS related settings\n",
    "if platform.system() == 'Windows':\n",
    "    print('Windows')\n",
    "#     %matplotlib tk\n",
    "    %matplotlib qt\n",
    "elif platform.system() == 'Darwin':\n",
    "    print('macOS')\n",
    "    Tk().withdraw()\n",
    "    %matplotlib osx\n",
    "elif platform == 'linux' or platform == 'linux2':\n",
    "    print('Linux')\n",
    "# This line of \"print\" must exist right after %matplotlib command, otherwise JN will hang on the first import statement after this.\n",
    "print('Interactive plot activated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6636ac83",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ChIQP\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "from cvxopt import solvers, matrix\n",
    "\n",
    "# Silencing solvers.qp\n",
    "from contextlib import redirect_stdout\n",
    "from io import StringIO\n",
    "class NullIO(StringIO):\n",
    "    def write(self, txt):\n",
    "        pass\n",
    "\n",
    "\n",
    "def silent(fn):\n",
    "    \"\"\"Decorator to silence functions.\"\"\"\n",
    "    def silent_fn(*args, **kwargs):\n",
    "        with redirect_stdout(NullIO()):\n",
    "            return fn(*args, **kwargs)\n",
    "    return silent_fn\n",
    "\n",
    "\n",
    "class Choquet_Integral_QP:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Instantiation of a ChoquetIntegral.\n",
    "           This sets up the ChI. It doesn't take any input parameters\n",
    "           because you may want to use pass your own values in(as opposed\n",
    "           to learning from data). To instatiate, use\n",
    "           chi = ChoquetIntegral.ChoquetIntegral()\n",
    "        \"\"\"\n",
    "        self.trainSamples, self.trainLabels = [], []\n",
    "        self.testSamples, self.testLabels = [], []\n",
    "        self.N, self.numberConstraints, self.M = 0, 0, 0\n",
    "        self.g = 0\n",
    "        self.fm = []\n",
    "        self.type = []\n",
    "\n",
    "\n",
    "    def train_chi(self, x1, l1):\n",
    "        \"\"\"\n",
    "        This trains this instance of your ChoquetIntegral w.r.t x1 and l1.\n",
    "        :param x1: These are the training samples of size N x M(inputs x number of samples)\n",
    "        :param l1: These are the training labels of size 1 x M(label per sample)\n",
    "        \"\"\"\n",
    "        self.type = 'quad'\n",
    "        self.trainSamples = x1\n",
    "        self.trainLabels = l1\n",
    "        self.N = self.trainSamples.shape[0]\n",
    "        self.M = self.trainSamples.shape[1]\n",
    "#         print(\"Number Inputs : \", self.N, \"; Number Samples : \", self.M)\n",
    "        self.fm = self.produce_lattice()\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "    def chi_quad(self, x2):\n",
    "        \"\"\"\n",
    "        This will produce an output for this instance of the ChI\n",
    "        This will use the learned(or specified) Choquet integral to\n",
    "        produce an output w.r.t. to the new input.\n",
    "        :param x2: testing sample\n",
    "        :return: output of the choquet integral.\n",
    "        \"\"\"\n",
    "        if self.type == 'quad':\n",
    "            n = len(x2)\n",
    "            pi_i = np.argsort(x2)[::-1][:n] + 1\n",
    "            ch = x2[pi_i[0] - 1] * (self.fm[str(pi_i[:1])])\n",
    "            for i in range(1, n):\n",
    "                latt_pti = np.sort(pi_i[:i + 1])\n",
    "                latt_ptimin1 = np.sort(pi_i[:i])\n",
    "                ch = ch + x2[pi_i[i] - 1] * (self.fm[str(latt_pti)] - self.fm[str(latt_ptimin1)])\n",
    "            return ch\n",
    "        else:\n",
    "            print(\"If using sugeno measure, you need to use chi_sugeno.\")\n",
    "\n",
    "\n",
    "    def produce_lattice(self):\n",
    "        \"\"\"\n",
    "            This method builds is where the lattice(or FM variables) will be learned.\n",
    "            The FM values can be found via a quadratic program, which is used here\n",
    "            after setting up constraint matrices. Refer to papers for complete overview.\n",
    "        :return: Lattice, the learned FM variables.\n",
    "        \"\"\"\n",
    "\n",
    "        fm_len = 2 ** self.N - 1  # nc\n",
    "        E = np.zeros((fm_len, fm_len))  # D\n",
    "        L = np.zeros(fm_len)  # f\n",
    "        index_keys = self.get_keys_index()\n",
    "        for i in range(0, self.M):  # it's going through one sample at a time.\n",
    "            l = self.trainLabels[i]  # this is the labels\n",
    "            fm_coeff = self.get_fm_class_img_coeff(index_keys, self.trainSamples[:, i], fm_len)  # this is Hdiff\n",
    "            # print(fm_coeff)\n",
    "            L = L + (-2) * l * fm_coeff\n",
    "            E = E + np.matmul(fm_coeff.reshape((fm_len, 1)), fm_coeff.reshape((1, fm_len)))\n",
    "\n",
    "        G, h, A, b = self.build_constraint_matrices(index_keys, fm_len)\n",
    "        solvers_qp = silent(solvers.qp)\n",
    "        sol = solvers_qp(matrix(2 * E, tc='d'), matrix(L.T, tc='d'), matrix(G, tc='d'), matrix(h, tc='d'),\n",
    "                         matrix(A, tc='d'), matrix(b, tc='d'))\n",
    "        g = sol['x']\n",
    "        Lattice = {}\n",
    "        for key in index_keys.keys():\n",
    "            Lattice[key] = g[index_keys[key]]\n",
    "        return Lattice\n",
    "\n",
    "\n",
    "    def build_constraint_matrices(self, index_keys, fm_len):\n",
    "        \"\"\"\n",
    "        This method builds the necessary constraint matrices.\n",
    "        :param index_keys: map to reference lattice components\n",
    "        :param fm_len: length of the fuzzy measure\n",
    "        :return: the constraint matrices\n",
    "        \"\"\"\n",
    "\n",
    "        vls = np.arange(1, self.N + 1)\n",
    "        line = np.zeros(fm_len)\n",
    "        G = line\n",
    "        line[index_keys[str(np.array([1]))]] = -1.\n",
    "        h = np.array([0])\n",
    "        for i in range(2, self.N + 1):\n",
    "            line = np.zeros(fm_len)\n",
    "            line[index_keys[str(np.array([i]))]] = -1.\n",
    "            G = np.vstack((G, line))\n",
    "            h = np.vstack((h, np.array([0])))\n",
    "        for i in range(2, self.N + 1):\n",
    "            parent = np.array(list(itertools.combinations(vls, i)))\n",
    "            for latt_pt in parent:\n",
    "                for j in range(len(latt_pt) - 1, len(latt_pt)):\n",
    "                    children = np.array(list(itertools.combinations(latt_pt, j)))\n",
    "                    for latt_ch in children:\n",
    "                        line = np.zeros(fm_len)\n",
    "                        line[index_keys[str(latt_ch)]] = 1.\n",
    "                        line[index_keys[str(latt_pt)]] = -1.\n",
    "                        G = np.vstack((G, line))\n",
    "                        h = np.vstack((h, np.array([0])))\n",
    "\n",
    "        line = np.zeros(fm_len)\n",
    "        line[index_keys[str(vls)]] = 1.\n",
    "        G = np.vstack((G, line))\n",
    "        h = np.vstack((h, np.array([1])))\n",
    "\n",
    "        # equality constraints\n",
    "        A = np.zeros((1, fm_len))\n",
    "        A[0, -1] = 1\n",
    "        b = np.array([1]);\n",
    "\n",
    "        return G, h, A, b\n",
    "\n",
    "\n",
    "    def get_fm_class_img_coeff(self, Lattice, h, fm_len):  # Lattice is FM_name_and_index, h is the samples, fm_len\n",
    "        \"\"\"\n",
    "        This creates a FM map with the name as the key and the index as the value\n",
    "        :param Lattice: dictionary with FM\n",
    "        :param h: sample\n",
    "        :param fm_len: fm length\n",
    "        :return: the fm_coeff\n",
    "        \"\"\"\n",
    "\n",
    "        n = len(h)  # len(h) is the number of the samples\n",
    "        fm_coeff = np.zeros(fm_len)\n",
    "        pi_i = np.argsort(-h) + 1\n",
    "        for i in range(1, n):\n",
    "            fm_coeff[Lattice[str(np.sort(pi_i[:i]))]] = h[pi_i[i - 1] - 1] - h[pi_i[i] - 1]\n",
    "        fm_coeff[Lattice[str(np.sort(pi_i[:n]))]] = h[pi_i[n - 1] - 1]\n",
    "        np.matmul(fm_coeff, np.transpose(fm_coeff))\n",
    "        return fm_coeff\n",
    "\n",
    "\n",
    "    def get_keys_index(self):\n",
    "        \"\"\"\n",
    "        Sets up a dictionary for referencing FM.\n",
    "        :return: The keys to the dictionary\n",
    "        \"\"\"\n",
    "\n",
    "        vls = np.arange(1, self.N + 1)\n",
    "        count = 0\n",
    "        Lattice = {}\n",
    "        for i in range(0, self.N):\n",
    "            Lattice[str(np.array([vls[i]]))] = count\n",
    "            count = count + 1\n",
    "        for i in range(2, self.N + 1):\n",
    "            A = np.array(list(itertools.combinations(vls, i)))\n",
    "            for latt_pt in A:\n",
    "                Lattice[str(latt_pt)] = count\n",
    "                count = count + 1\n",
    "        return Lattice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4bcb22a",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def create_dataset(dim, all_perms, num_per_perm, superset_factor):\n",
    "    \"\"\"\n",
    "    Create a dataset with all possible permutation, with each permutation having the same number of samples.\n",
    "    \n",
    "    :param dim: Dimension of data sample\n",
    "    :param all_perms: A list of permutation. \n",
    "                       Use as an input so that the algorithm creates data for different permutations in the order assigned.\n",
    "    :param num_per_perm: Number of data samples for each permutation\n",
    "    :param superset_factor: Data for each permutation are pulled from a randomly generated dataset. \n",
    "                            To ensure that each permutation gets at least #num_per_perm# data samples,\n",
    "                            create a dataset #superset_factor* times (normally 3 will be enough) bigger than the dataset wanted.\n",
    "    \"\"\"\n",
    "    # Every permutation gets the same number of train/test data samples,\n",
    "    # To ensure that, calculate the number of data needed in total, \n",
    "    # and generate a super dataset that is multiple times bigger.\n",
    "    num = math.factorial(dim) * num_per_perm\n",
    "    # Create superset\n",
    "    data_superset = np.random.rand(dim, num*superset_factor)\n",
    "    # Get permutation of each data sample\n",
    "    data_perms = np.argsort(data_superset, 0)\n",
    "    # N! possible permutations\n",
    "#     all_perms = list(permutations(list(range(dim))))\n",
    "    # Group data sample according to its permutation\n",
    "    data_idx_superset_by_perm = []\n",
    "    \n",
    "    for i, current_perm in enumerate(all_perms):\n",
    "        # Get index of data sample of certain permutation and save to list\n",
    "        temp = np.where(data_perms[0, :]==current_perm[0])\n",
    "        for idx, p in enumerate(current_perm):\n",
    "            temp = np.intersect1d(temp, np.where(data_perms[idx, :]==p))\n",
    "        if temp.size < num_per_perm:\n",
    "            print('Current permutation doesn\\'t have sufficient number of samples. Please regenerate!')\n",
    "            exit()\n",
    "        data_idx_superset_by_perm.append(temp)\n",
    "    \n",
    "    # Every permutation gets the same number of train/test data samples,\n",
    "    # Data is randomly pull from superset each epoch\n",
    "    data_idx_by_perm = []\n",
    "    for i in range(len(all_perms)):\n",
    "        temp = data_idx_superset_by_perm[i]\n",
    "        random.shuffle(temp)\n",
    "        data_idx_by_perm.append(temp[0:num_per_perm])\n",
    "        \n",
    "    return data_superset, data_idx_superset_by_perm, data_idx_by_perm\n",
    "\n",
    "\n",
    "def gmean(dim):\n",
    "    return lambda x, d: np.power(np.prod(x, d), 1/dim)\n",
    "\n",
    "\n",
    "def w_avg(dim, idx):\n",
    "    if dim == 3:\n",
    "        if idx == 0:\n",
    "            return lambda x, d: np.average(x, d, [0.8, 0.1, 0.1])\n",
    "        elif idx == 1:\n",
    "            return lambda x, d: np.average(x, d, [0.2, 0.7, 0.1])\n",
    "        elif idx == 2:\n",
    "            return lambda x, d: np.average(x, d, [0.5, 0.2, 0.3])\n",
    "        elif idx == 3:\n",
    "            return lambda x, d: np.average(x, d, [0.1, 0.3, 0.5])\n",
    "        \n",
    "    elif dim == 4:\n",
    "        if idx == 0:\n",
    "            return lambda x, d: np.average(x, d, [0.1, 0.2, 0.3, 0.4])\n",
    "        elif idx == 1:\n",
    "            return lambda x, d: np.average(x, d, [0.2, 0.2, 0.2, 0.4])\n",
    "        elif idx == 2:\n",
    "            return lambda x, d: np.average(x, d, [0, 0.1, 0.3, 0.6])\n",
    "        elif idx == 3:\n",
    "            return lambda x, d: np.average(x, d, [0, 0, 0.4, 0.6])\n",
    "        \n",
    "\n",
    "\n",
    "def cal_chi(fm, x):\n",
    "    \"\"\"\n",
    "    Calculates ChI with given fuzzy measure and input\n",
    "    \n",
    "    :param fm: Fuzzy measure\n",
    "    :param x: Input\n",
    "    :return: Single value Chi output\n",
    "    \"\"\"\n",
    "    pi_i = np.argsort(-x) + 1 # Arg sort of input, with the smallest index being 1\n",
    "    ch = x[pi_i[0] - 1] * (fm[str(pi_i[:1])])\n",
    "    for i in range(1, len(x)):\n",
    "        latt_pti = np.sort(pi_i[:i+1])\n",
    "        latt_ptimin1 = np.sort(pi_i[:i])\n",
    "        ch = ch + x[pi_i[i] - 1] * (fm[str(latt_pti)] - fm[str(latt_ptimin1)])\n",
    "    return ch\n",
    "\n",
    "\n",
    "def get_cal_chi(fm):\n",
    "    return lambda x: cal_chi(fm, x)\n",
    "\n",
    "\n",
    "# Convert decimal to binary string\n",
    "def sources_and_subsets_nodes(N):\n",
    "    str1 = \"{0:{fill}\"+str(N)+\"b}\"\n",
    "    a = []\n",
    "    for i in range(1,2**N):\n",
    "        a.append(str1.format(i, fill='0'))\n",
    "\n",
    "    sourcesInNode = []\n",
    "    sourcesNotInNode = []\n",
    "    subset = []\n",
    "    sourceList = list(range(N))\n",
    "    # find subset nodes of a node\n",
    "    def node_subset(node, sourcesInNodes):\n",
    "        return [node - 2**(i) for i in sourcesInNodes]\n",
    "    \n",
    "    # convert binary encoded string to integer list\n",
    "    def string_to_integer_array(s, ch):\n",
    "        N = len(s) \n",
    "        return [(N - i - 1) for i, ltr in enumerate(s) if ltr == ch]\n",
    "    \n",
    "    for j in range(len(a)):\n",
    "        # index from right to left\n",
    "        idxLR = string_to_integer_array(a[j],'1')\n",
    "        sourcesInNode.append(idxLR)  \n",
    "        sourcesNotInNode.append(list(set(sourceList) - set(idxLR)))\n",
    "        subset.append(node_subset(j,idxLR))\n",
    "\n",
    "    return sourcesInNode, subset\n",
    "\n",
    "\n",
    "def get_keys_index(dim):\n",
    "    \"\"\"\n",
    "    Sets up a dictionary for referencing FM.\n",
    "    :return: The keys to the dictionary\n",
    "    \"\"\"\n",
    "    vls = np.arange(1, dim + 1)\n",
    "    Lattice = {}\n",
    "    for i in range(1, dim + 1):\n",
    "        A = np.array(list(itertools.combinations(vls, i)))\n",
    "        for latt_pt in A:\n",
    "            Lattice[str(latt_pt)] = 1\n",
    "    return Lattice\n",
    "\n",
    "\n",
    "def get_min_fm_target(dim):\n",
    "    fm = get_keys_index(dim)\n",
    "    for key in fm.keys():\n",
    "        if len(key.split()) != dim:\n",
    "            fm[key] = 0\n",
    "        else:\n",
    "            fm[key] = 1\n",
    "    return fm\n",
    "    \n",
    "    \n",
    "def get_max_fm_target(dim):\n",
    "    fm = get_keys_index(dim)\n",
    "    return fm\n",
    "\n",
    "\n",
    "def get_mean_fm_target(dim):\n",
    "    fm = get_keys_index(dim)\n",
    "    for key in fm.keys():\n",
    "        fm[key] = len(key.split()) / dim\n",
    "    return fm\n",
    "\n",
    "\n",
    "def get_gmean_fm_target(dim):\n",
    "    fm = get_mean_fm_target(dim)\n",
    "    return fm\n",
    "\n",
    "\n",
    "def w_avg_target(dim, weight):\n",
    "    fm = get_keys_index(dim)\n",
    "    for idx, key in enumerate(fm.keys()):\n",
    "        if len(key.split()) == 1:\n",
    "            fm[key] = weight[idx]\n",
    "        elif len(key.split()) == 2:\n",
    "            key1 = int(key[1:-1].split()[0])\n",
    "            key2 = int(key[1:-1].split()[1])\n",
    "            fm[key] = weight[key1-1] + weight[key2-1]\n",
    "        elif len(key.split()) == 3:\n",
    "            key1 = key[1:-1].split()[0]\n",
    "            key2 = key[1:-1].split()[1]\n",
    "            key3 = int(key[1:-1].split()[2])\n",
    "            key12 = '[' + key1 + ' ' + key2 + ']'\n",
    "            fm[key] = fm[key12] + weight[key3-1]\n",
    "    return fm\n",
    "\n",
    "def get_w_avg_target(weight):\n",
    "    return lambda dim: w_avg_target(dim, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066a2f3d",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-43ce67fec7e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mperc\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_perms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0mtest_label_unseen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meva_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_d_unseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                     \u001b[0mtest_out_unseen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_cal_chi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_d_unseen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                     \u001b[0mMSEs_unseen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meva_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperc_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrep\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_out_unseen\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtest_label_unseen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mFM_by_dim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/nn/lib/python3.8/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0mbuff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mbuff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minarr_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-9f54089c1644>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_cal_chi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcal_chi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-9f54089c1644>\u001b[0m in \u001b[0;36mcal_chi\u001b[0;34m(fm, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mlatt_pti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mlatt_ptimin1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpi_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatt_pti\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatt_ptimin1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/nn/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_array_str_implementation\u001b[0;34m(a, max_line_width, precision, suppress_small, array2string)\u001b[0m\n\u001b[1;32m   1515\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_guarded_repr_or_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1517\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray2string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_line_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuppress_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/nn/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36marray2string\u001b[0;34m(a, max_line_width, precision, suppress_small, separator, prefix, style, formatter, threshold, edgeitems, sign, floatmode, suffix, legacy)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"[]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_array2string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/nn/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mrepr_running\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 \u001b[0mrepr_running\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/nn/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_array2string\u001b[0;34m(a, options, separator, prefix)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;31m# find the right formatting function for the array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m     \u001b[0mformat_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_format_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m     \u001b[0;31m# skip over \"[\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/nn/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_get_format_function\u001b[0;34m(data, **options)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mformatdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timedelta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mformatdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtypeobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtypeobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlongfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/nn/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    363\u001b[0m     formatdict = {\n\u001b[1;32m    364\u001b[0m         \u001b[0;34m'bool'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBoolFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0;34m'int'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIntegerFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         'float': lambda: FloatingFormat(\n\u001b[1;32m    367\u001b[0m             data, precision, floatmode, suppress, sign, legacy=legacy),\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/nn/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             max_str_len = max(len(str(np.max(data))),\n\u001b[0;32m-> 1154\u001b[0;31m                               len(str(np.min(data))))\n\u001b[0m\u001b[1;32m   1155\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0mmax_str_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/nn/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2856\u001b[0m     \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m     \"\"\"\n\u001b[0;32m-> 2858\u001b[0;31m     return _wrapreduction(a, np.minimum, 'min', axis, None, out,\n\u001b[0m\u001b[1;32m   2859\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   2860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/nn/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     passkwargs = {k: v for k, v in kwargs.items()\n\u001b[1;32m     72\u001b[0m                   if v is not np._NoValue}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run\n",
    "\n",
    "# Parameters\n",
    "num_repetition = 1\n",
    "dim_list = list(range(3, 5)) \n",
    "num_per_perm_train = 100 # Every permutation gets the same number of train/test data samples\n",
    "num_per_perm_test = 20 # Every permutation gets the same number of train/test data samples\n",
    "superset_factor = 4 # Create a superset # times larger than what is needed to ensure each class would have sufficient number of samples\n",
    "eva_funcs = [np.amin, np.amax, np.mean, w_avg(2, 0), w_avg(2, 1), w_avg(2, 2), w_avg(2, 3)] # List of evaluation functions, initialize with dim=2\n",
    "\n",
    "MSEs_seen_by_dim = []\n",
    "MSEs_unseen_by_dim = []\n",
    "\n",
    "FM_by_dim = []\n",
    "\n",
    "output_dir = 'output/'\n",
    "\n",
    "# Train&Test for dim = 3 to 8\n",
    "for dim in dim_list:\n",
    "#     eva_funcs[-1] = gmean(dim) # List of evaluation functions\n",
    "    for avg_idx in range(4):\n",
    "        eva_funcs[avg_idx+3] = w_avg(dim, avg_idx)\n",
    "    \n",
    "    all_perms = list(permutations(list(range(dim)))) # N! possible permutations\n",
    "\n",
    "    # When the # of possible permutations exceed certain number (in here 5!), \n",
    "    #instead of feeding only one more permutation a time, feed more.\n",
    "    train_group_num_limit = math.factorial(5)\n",
    "    if len(all_perms) > train_group_num_limit:\n",
    "        step = int(len(all_perms) / train_group_num_limit)\n",
    "    else:\n",
    "        step = 1\n",
    "    \n",
    "    # Mean Squared Error for each evaluation function, for each percentage, for each repetition, of all test samples, for both seen and unseen data.\n",
    "    MSEs_seen = np.zeros((len(eva_funcs), len(range(step-1, len(all_perms), step)), num_repetition))\n",
    "    MSEs_unseen = np.zeros((len(eva_funcs), len(range(step-1, len(all_perms), step))-1, num_repetition))\n",
    "    # Record FM after train session with both seen and unseen data pattern\n",
    "    FM = np.zeros((len(eva_funcs), len(range(step-1, len(all_perms), step)), num_repetition, 2**dim-1))\n",
    "    \n",
    "    for rep in range(num_repetition):\n",
    "        print('Repetition:', rep+1)\n",
    "        random.shuffle(all_perms)\n",
    "        train_data_superset, _, train_idx_by_perm = create_dataset(dim, all_perms, num_per_perm_train, superset_factor)\n",
    "        test_data_superset, _, test_idx_by_perm = create_dataset(dim, all_perms, num_per_perm_test, superset_factor)\n",
    "        \n",
    "        for perc_idx, perc in enumerate(tqdm(range(step-1, len(all_perms), step))):\n",
    "            # Find index of train/test sample in superset and shuffle\n",
    "            train_idx = np.concatenate(train_idx_by_perm[0:perc+1])\n",
    "            np.random.shuffle(train_idx)\n",
    "            test_idx = np.concatenate(test_idx_by_perm[0:perc+1])\n",
    "            # Find data sample through index\n",
    "            train_d = train_data_superset[:, train_idx]\n",
    "            test_d = test_data_superset[:, test_idx]\n",
    "            # Define unseen test data samples when the train data doesn't cover 100% of the permutation\n",
    "            if perc < len(all_perms)-1:\n",
    "                test_idx_unseen = np.concatenate(test_idx_by_perm[perc+1:])\n",
    "                test_d_unseen = test_data_superset[:, test_idx_unseen]\n",
    "            else:\n",
    "                test_d_unseen = []\n",
    "                \n",
    "            # Define subsets of 'X', or keys for fuzzy measure. Like '1 2' or '1 3 4 5' for g(x1, x2) or g(x1, x3, x4, x5)\n",
    "            sourcesInNode, subset = sources_and_subsets_nodes(dim)\n",
    "            keys = [str(np.sort(i)+1) for i in sourcesInNode]\n",
    "            \n",
    "            for eva_idx, eva_func in enumerate(eva_funcs):\n",
    "                # Calculate label with given evaluation function\n",
    "                train_label = eva_func(train_d, 0)\n",
    "                test_label = eva_func(test_d, 0)\n",
    "                # Initialize ChIQP\n",
    "                chiqp = Choquet_Integral_QP()\n",
    "                # Train \n",
    "                chiqp.train_chi(train_d, train_label)\n",
    "                # Get fuzzy measure learned\n",
    "                fm = chiqp.fm\n",
    "                FM[eva_idx, perc_idx, rep, :] = np.asarray(list(fm.values()))\n",
    "                # Calculate result from integral with test data\n",
    "                test_output = np.apply_along_axis(get_cal_chi(fm), 0, test_d)\n",
    "                MSE = ((test_output - test_label)**2).mean()\n",
    "                MSEs_seen[eva_idx, perc_idx, rep] = MSE\n",
    "                # Calculate result from integral with test data - unseen\n",
    "                if perc < len(all_perms)-1:\n",
    "                    test_label_unseen = eva_func(test_d_unseen, 0)\n",
    "                    test_out_unseen = np.apply_along_axis(get_cal_chi(fm), 0, test_d_unseen)\n",
    "                    MSEs_unseen[eva_idx, perc_idx, rep] = ((test_out_unseen - test_label_unseen)**2).mean()\n",
    "    FM_by_dim.append(FM)\n",
    "    MSEs_seen_by_dim.append(MSEs_seen)\n",
    "    MSEs_unseen_by_dim.append(MSEs_unseen)\n",
    "\n",
    "with open(output_dir + 'ChIQP_saved_file', 'wb') as f:\n",
    "    pickle.dump(FM_by_dim, f)\n",
    "    pickle.dump(MSEs_seen_by_dim, f)\n",
    "    pickle.dump(MSEs_unseen_by_dim, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "948802b1",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Plot for seen data\n",
    "output_dir = 'output/'\n",
    "dim_list = list(range(4, 5)) \n",
    "eva_funcs = [np.amin, np.amax, np.mean, gmean(2)]\n",
    "\n",
    "with open(output_dir + 'ChIQP_saved_file', 'rb') as f:\n",
    "    FM_by_dim = pickle.load(f)\n",
    "    MSEs_seen_by_dim = pickle.load(f)\n",
    "    MSEs_unseen_by_dim = pickle.load(f)\n",
    "\n",
    "for dim, MSEs_seen in zip(dim_list, MSEs_seen_by_dim):\n",
    "    plot_mean = np.mean(MSEs_seen, 2)\n",
    "    plot_max = np.max(MSEs_seen, 2)\n",
    "    plot_min = np.min(MSEs_seen, 2)\n",
    "\n",
    "    num_perm = math.factorial(dim)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    x = (np.asarray(list(range(1, np.size(MSEs_seen, 1)+1)))) / np.size(MSEs_seen, 1)\n",
    "    plt.plot(x, plot_mean.transpose())\n",
    "    ax.set_title('MSE (Data with seen pattern)')\n",
    "    \n",
    "    if dim == 3:\n",
    "        ax.legend(['Min', 'Max', 'Mean', '8 1 1', '2 7 1', '5 2 3', '1 3 5'])\n",
    "    elif dim == 4:\n",
    "        ax.legend(['Min', 'Max', 'Mean', '1 2 3 4', '2 2 2 4', '0 1 3 6', '0 0 4 6'])\n",
    "        \n",
    "    ax.set_xlabel('Percentage of Seen Data')\n",
    "    ax.set_ylabel('MSEs avg')\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter('{0:.0%}'.format))\n",
    "\n",
    "    for i in range(len(eva_funcs)):\n",
    "        plt.fill_between(x, plot_min[i, :], plot_max[i, :], alpha=0.1)\n",
    "    \n",
    "    plt.savefig(output_dir + 'ChIQP-' + str(dim) + '-MSE seen.png')\n",
    "    \n",
    "    \n",
    "    \n",
    "# Plot for unseen data\n",
    "\n",
    "for dim, MSEs_unseen in zip(dim_list, MSEs_unseen_by_dim):\n",
    "    plot_mean = np.mean(MSEs_unseen, 2)\n",
    "    plot_max = np.max(MSEs_unseen, 2)\n",
    "    plot_min = np.min(MSEs_unseen, 2)\n",
    "\n",
    "    num_perm = math.factorial(dim)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    x = (np.asarray(list(range(1, np.size(MSEs_unseen, 1)+1)))) / (np.size(MSEs_unseen, 1)+1)\n",
    "    plt.plot(x, plot_mean.transpose())\n",
    "    ax.set_title('MSE (Data with unseen pattern)')\n",
    "    \n",
    "    if dim == 3:\n",
    "        print(dim)\n",
    "        ax.legend(['Min', 'Max', 'Mean', '8 1 1', '2 7 1', '5 2 3', '1 3 5'])\n",
    "    elif dim == 4:\n",
    "        print(dim)\n",
    "        ax.legend(['Min', 'Max', 'Mean', '1 2 3 4', '2 2 2 4', '0 1 3 6', '0 0 4 6'])\n",
    "        \n",
    "    ax.set_xlabel('Percentage of Seen Data')\n",
    "    ax.set_ylabel('MSEs avg')\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter('{0:.0%}'.format))\n",
    "\n",
    "    for i in range(len(eva_funcs)):\n",
    "        plt.fill_between(x, plot_min[i, :], plot_max[i, :], alpha=0.1)\n",
    "        \n",
    "    plt.savefig(output_dir + 'ChIQP-' + str(dim) + '-MSE unseen.png')\n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be7d5ef8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for fm, dim in zip(FM_by_dim, dim_list):\n",
    "    if dim == 3:\n",
    "        eva_name = ['Min', 'Max', 'Mean', '8 1 1', '2 7 1', '5 2 3', '1 3 5']\n",
    "        fm_targets = [get_min_fm_target, get_max_fm_target, get_mean_fm_target, get_w_avg_target([.8, .1, .1]), get_w_avg_target([.2, .7, .1]), get_w_avg_target([.5, .2, .3]), get_w_avg_target([.1, .3, .5])]\n",
    "    if dim == 4:\n",
    "        eva_name = ['Min', 'Max', 'Mean', '1 2 3 4', '2 2 2 4', '0 1 3 6', '0 0 4 6']\n",
    "        fm_targets = [get_min_fm_target, get_max_fm_target, get_mean_fm_target, get_w_avg_target([.1, .2, .3, .4]), get_w_avg_target([.2, .2, .2, .4]), get_w_avg_target([0, .1, .3, .6]), get_w_avg_target([0, 0, .4, .6])]\n",
    "    for eva_idx, fm_target in enumerate(fm_targets):\n",
    "        \n",
    "        eva_fm = fm[eva_idx, :, :, :]\n",
    "        eva_fm_mean = np.mean(eva_fm, 1)\n",
    "        eva_fm_min = np.amin(eva_fm, 1)\n",
    "        eva_fm_max = np.amax(eva_fm, 1)\n",
    "        \n",
    "        # First set up the figure, the axis, and the plot element we want to animate\n",
    "        fig = plt.figure()\n",
    "        ax = plt.axes(xlim=(0, np.size(eva_fm, 2)-1), ylim=(-0.1, 1.1))\n",
    "        line, = ax.plot([], [], lw=2)\n",
    "        ax.set_xlabel('Fuzzy Measure Value')\n",
    "        ax.set_ylabel('Fuzzy Measure Count')\n",
    "        ax.set_title(eva_name[eva_idx]+' Dim='+str(dim))\n",
    "        \n",
    "        # initialization function: plot the background of each frame\n",
    "        def init():\n",
    "            x = list(range(np.size(eva_fm, 2)))\n",
    "            y = list(fm_target(dim).values())\n",
    "            plt.plot(x, y)\n",
    "            ax.legend(['FM Target'], loc=4)\n",
    "            \n",
    "\n",
    "        # animation function.  This is called sequentially\n",
    "        def animate(i):\n",
    "            x = np.asarray(list(range(np.size(eva_fm, 2))))\n",
    "            y = eva_fm_mean[i, :]\n",
    "            line.set_data(x, y)\n",
    "            ax.legend(['FM Predict (Seen data percentage ' + str(\"{0:.0%}\".format((i+1)/np.size(eva_fm, 0))) + ')', 'FM Target'])\n",
    "            ax.collections = []\n",
    "            plt.fill_between(x, eva_fm_min[i, :], eva_fm_max[i, :], color='blue', alpha=0.1)\n",
    "            return line,\n",
    "\n",
    "        # call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "        anim = animation.FuncAnimation(fig, animate, frames=np.size(eva_fm, 0), init_func=init(), interval=200, blit=True)\n",
    "\n",
    "        # save the animation as an mp4.  This requires ffmpeg or mencoder to be\n",
    "        # installed.  The extra_args ensure that the x264 codec is used, so that\n",
    "        # the video can be embedded in html5.  You may need to adjust this for\n",
    "        # your system: for more information, see\n",
    "        # http://matplotlib.sourceforge.net/api/animation_api.html\n",
    "        anim.save(output_dir + 'ChIQP-' + str(dim) + '-' + eva_name[eva_idx] + 'FM.mp4', fps=3)\n",
    "#         plt.show()\n",
    "        plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
