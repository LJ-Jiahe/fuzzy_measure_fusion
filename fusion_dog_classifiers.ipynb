{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2911dfaf",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, models,datasets\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3419971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pretrained models on imagenet\n",
    "\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "squeezenet = models.squeezenet1_0(pretrained=True)\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "densenet = models.densenet161(pretrained=True)\n",
    "inception = models.inception_v3(pretrained=True)\n",
    "googlenet = models.googlenet(pretrained=True)\n",
    "shufflenet = models.shufflenet_v2_x1_0(pretrained=True)\n",
    "mobilenet_v2 = models.mobilenet_v2(pretrained=True)\n",
    "mobilenet_v3_large = models.mobilenet_v3_large(pretrained=True)\n",
    "mobilenet_v3_small = models.mobilenet_v3_small(pretrained=True)\n",
    "resnext50_32x4d = models.resnext50_32x4d(pretrained=True)\n",
    "wide_resnet50_2 = models.wide_resnet50_2(pretrained=True)\n",
    "mnasnet = models.mnasnet1_0(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "122536f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Dog dataloader\n",
    "\n",
    "batch_size = 500\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize(256),\n",
    "     transforms.CenterCrop(224),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class SimpleDog(Dataset):\n",
    "    def __init__(self, image_path, transform=None):\n",
    "        super(SimpleDog, self).__init__()\n",
    "        self.data = datasets.ImageFolder(image_path, transform)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.data[idx]\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "img_path = r'./data/Stanford Dogs Dataset'\n",
    "# print(os.listdir(img_path))\n",
    "\n",
    "# dog_data = SimpleDog(r'./data/Stanford Dogs Dataset',  batch_size=1, transform=transform)\n",
    "\n",
    "dog_data = datasets.ImageFolder(img_path, transform)\n",
    "dog_loader = DataLoader(dog_data, batch_size=batch_size)\n",
    "dog_iter = iter(dog_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a69e5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lj_ji\\anaconda3\\envs\\nn\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "# Put data through multiple pretrained models\n",
    "images, labels = dog_iter.next()\n",
    "\n",
    "sm = torch.nn.Softmax(dim=1)\n",
    "\n",
    "# Output from VGG1\n",
    "output_vgg = vgg16(images)\n",
    "output_vgg_simple = output_vgg[:, [196, 265]]\n",
    "output_vgg_simple_sm = sm(output_vgg_simple)\n",
    "\n",
    "# Output from Mobilenet\n",
    "output_mobile = mobilenet_v3_large(images)\n",
    "output_mobile_simple = output_mobile[:, [196, 265]]\n",
    "output_mobile_simple_sm = sm(output_mobile_simple)\n",
    "\n",
    "# Output from Googlenet\n",
    "output_googlenet = googlenet(images)\n",
    "output_googlenet_simple = output_googlenet[:, [196, 265]]\n",
    "output_googlenet_simple_sm = sm(output_googlenet_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4e060d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one_hot(labels, num_classes):\n",
    "    one_hot = torch.zeros(len(labels), num_classes)\n",
    "    for i, label in enumerate(labels):\n",
    "        one_hot[i, label] = 1\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "labels_one_hot = make_one_hot(labels, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f9e3b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([305, 3])\n",
      "torch.Size([305, 3])\n"
     ]
    }
   ],
   "source": [
    "fusion_train_0 = torch.stack((output_vgg_simple_sm[:, 0], output_mobile_simple_sm[:, 0], output_googlenet_simple_sm[:, 0]), 1)\n",
    "fusion_train_1 = torch.stack((output_vgg_simple_sm[:, 1], output_mobile_simple_sm[:, 1], output_googlenet_simple_sm[:, 1]), 1)\n",
    "\n",
    "print(fusion_train_0.shape)\n",
    "print(fusion_train_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dc50c67",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ChINN\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Convert decimal to binary string\n",
    "def sources_and_subsets_nodes(N):\n",
    "    str1 = \"{0:{fill}\"+str(N)+\"b}\"\n",
    "    a = []\n",
    "    for i in range(1,2**N):\n",
    "        a.append(str1.format(i, fill='0'))\n",
    "\n",
    "    sourcesInNode = []\n",
    "    sourcesNotInNode = []\n",
    "    subset = []\n",
    "    sourceList = list(range(N))\n",
    "    # find subset nodes of a node\n",
    "    def node_subset(node, sourcesInNodes):\n",
    "        return [node - 2**(i) for i in sourcesInNodes]\n",
    "    \n",
    "    # convert binary encoded string to integer list\n",
    "    def string_to_integer_array(s, ch):\n",
    "        N = len(s) \n",
    "        return [(N - i - 1) for i, ltr in enumerate(s) if ltr == ch]\n",
    "    \n",
    "    for j in range(len(a)):\n",
    "        # index from right to left\n",
    "        idxLR = string_to_integer_array(a[j],'1')\n",
    "        sourcesInNode.append(idxLR)  \n",
    "        sourcesNotInNode.append(list(set(sourceList) - set(idxLR)))\n",
    "        subset.append(node_subset(j,idxLR))\n",
    "\n",
    "    return sourcesInNode, subset\n",
    "\n",
    "\n",
    "def subset_to_indices(indices):\n",
    "    return [i for i in indices]\n",
    "\n",
    "class Choquet_integral(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, N_in, N_out):\n",
    "        super(Choquet_integral,self).__init__()\n",
    "        self.N_in = N_in\n",
    "        self.N_out = N_out\n",
    "        self.nVars = 2**self.N_in - 2\n",
    "        \n",
    "        # The FM is initialized with mean\n",
    "        dummy = (1./self.N_in) * torch.ones((self.nVars, self.N_out), requires_grad=True)\n",
    "#        self.vars = torch.nn.Parameter( torch.Tensor(self.nVars,N_out))\n",
    "        self.vars = torch.nn.Parameter(dummy)\n",
    "        \n",
    "        # following function uses numpy vs pytorch\n",
    "        self.sourcesInNode, self.subset = sources_and_subsets_nodes(self.N_in)\n",
    "        \n",
    "        self.sourcesInNode = [torch.tensor(x) for x in self.sourcesInNode]\n",
    "        self.subset = [torch.tensor(x) for x in self.subset]\n",
    "        \n",
    "    def forward(self,inputs):    \n",
    "        self.FM = self.chi_nn_vars(self.vars)\n",
    "        sortInputs, sortInd = torch.sort(inputs,1, True)\n",
    "        M, N = inputs.size()\n",
    "        sortInputs = torch.cat((sortInputs, torch.zeros(M,1)), 1)\n",
    "        sortInputs = sortInputs[:,:-1] -  sortInputs[:,1:]\n",
    "        \n",
    "        out = torch.cumsum(torch.pow(2,sortInd),1) - torch.ones(1, dtype=torch.int64)\n",
    "        \n",
    "        data = torch.zeros((M,self.nVars+1))\n",
    "        \n",
    "        for i in range(M):\n",
    "            data[i,out[i,:]] = sortInputs[i,:] \n",
    "        \n",
    "        \n",
    "        ChI = torch.matmul(data,self.FM)\n",
    "            \n",
    "        return ChI\n",
    "    \n",
    "    # Converts NN-vars to FM vars\n",
    "    def chi_nn_vars(self, chi_vars):\n",
    "#        nVars,_ = chi_vars.size()\n",
    "        chi_vars = torch.abs(chi_vars)\n",
    "        #        nInputs = inputs.get_shape().as_list()[1]\n",
    "        \n",
    "        FM = chi_vars[None, 0,:]\n",
    "        for i in range(1,self.nVars):\n",
    "            indices = subset_to_indices(self.subset[i])\n",
    "            if (len(indices) == 1):\n",
    "                FM = torch.cat((FM,chi_vars[None,i,:]),0)\n",
    "            else:\n",
    "                #         ss=tf.gather_nd(variables, [[1],[2]])\n",
    "                maxVal,_ = torch.max(FM[indices,:],0)\n",
    "                temp = torch.add(maxVal,chi_vars[i,:])\n",
    "                FM = torch.cat((FM,temp[None,:]),0)\n",
    "              \n",
    "        FM = torch.cat([FM, torch.ones((1,self.N_out))],0)\n",
    "        FM = torch.min(FM, torch.ones(1))  \n",
    "        \n",
    "        return FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fa80eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-a71bd0bfb1fb>:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train,dtype=torch.float)\n",
      "<ipython-input-13-a71bd0bfb1fb>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label_train = torch.tensor(label_train,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Learned FMs:\n",
      "FM1 =  [0.8525713  0.35048088 1.         0.12938859 1.         0.6285027\n",
      " 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Fusion 0\n",
    "    \n",
    "# training samples size\n",
    "M = len(labels)\n",
    "\n",
    "# number of inputs\n",
    "N_in = 3\n",
    "\n",
    "# number of outputs aka number of Choquet integral neurons\n",
    "N_out = 1\n",
    "\n",
    "# Create a synthetic dataset via random sampling from a normal distribution with mean =-1 and std=2\n",
    "X_train = fusion_train_0\n",
    "\n",
    "# Let's specify the FMs  (There will be N_out number of FMs)\n",
    "# Herein we adopt binary encoding instead of lexicographic encoding to represent a FM that is easier to code. \n",
    "# As for example, an FM for three inputs using lexicographic encoding is, g = {g_1, g_2, g_3, g_{12}, g_{13}, g_{23}, g_{123}}.\n",
    "# whereas its binary encoding is g = {g_1, g_2, g_{12}, g_3 g_{13}, g_{23}, g_{123}}.\n",
    "\n",
    "# For simplicity, here we use OWA. \n",
    "\n",
    "\n",
    "\n",
    "# Generate the label or the groundtruth based on the provided FMs/OWAs. The labels are two dimentional\n",
    "label_train = labels_one_hot[:, 0].unsqueeze_(-1)\n",
    "\n",
    "# Now we want to recover the FMs from the training data and groundtruth\n",
    "# First, build a Choquet integral neuron with N_in inputs and N_out outputs\n",
    "net = Choquet_integral(N_in, N_out)\n",
    "\n",
    "# set the optimization algorithms and paramters the learning\n",
    "learning_rate = 0.3;\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)   \n",
    "\n",
    "num_epochs = 300;\n",
    "\n",
    "# convert from numpy to torch tensor\n",
    "X_train = torch.tensor(X_train,dtype=torch.float)\n",
    "label_train = torch.tensor(label_train,dtype=torch.float)\n",
    "\n",
    "# optimize\n",
    "for t in range(num_epochs):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = net(X_train)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = criterion(y_pred, label_train)\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()  \n",
    "\n",
    "# Finally, the learned FMs\n",
    "FM_learned = (net.chi_nn_vars(net.vars).cpu()).detach().numpy()\n",
    "print('\\n\\nLearned FMs:')\n",
    "print('FM1 = ', FM_learned[:,0])\n",
    "# print('FM2 = ',FM_learned[:,1])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e769ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-3e469623b98e>:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train,dtype=torch.float)\n",
      "<ipython-input-14-3e469623b98e>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label_train = torch.tensor(label_train,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Learned FMs:\n",
      "FM1 =  [0.4537986  0.01906862 0.9568969  0.01494275 0.6896283  0.0256345\n",
      " 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Fusion 1\n",
    "\n",
    "# training samples size\n",
    "M = len(labels)\n",
    "\n",
    "# number of inputs\n",
    "N_in = 3\n",
    "\n",
    "# number of outputs aka number of Choquet integral neurons\n",
    "N_out = 1\n",
    "\n",
    "# Create a synthetic dataset via random sampling from a normal distribution with mean =-1 and std=2\n",
    "X_train = fusion_train_1\n",
    "\n",
    "# Let's specify the FMs  (There will be N_out number of FMs)\n",
    "# Herein we adopt binary encoding instead of lexicographic encoding to represent a FM that is easier to code. \n",
    "# As for example, an FM for three inputs using lexicographic encoding is, g = {g_1, g_2, g_3, g_{12}, g_{13}, g_{23}, g_{123}}.\n",
    "# whereas its binary encoding is g = {g_1, g_2, g_{12}, g_3 g_{13}, g_{23}, g_{123}}.\n",
    "\n",
    "# For simplicity, here we use OWA. \n",
    "\n",
    "\n",
    "\n",
    "# Generate the label or the groundtruth based on the provided FMs/OWAs. The labels are two dimentional\n",
    "label_train = labels_one_hot[:, 1].unsqueeze_(-1)\n",
    "\n",
    "# Now we want to recover the FMs from the training data and groundtruth\n",
    "# First, build a Choquet integral neuron with N_in inputs and N_out outputs\n",
    "net = Choquet_integral(N_in, N_out)\n",
    "\n",
    "# set the optimization algorithms and paramters the learning\n",
    "learning_rate = 0.3;\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)   \n",
    "\n",
    "num_epochs = 300;\n",
    "\n",
    "# convert from numpy to torch tensor\n",
    "X_train = torch.tensor(X_train,dtype=torch.float)\n",
    "label_train = torch.tensor(label_train,dtype=torch.float)\n",
    "\n",
    "# optimize\n",
    "for t in range(num_epochs):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = net(X_train)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = criterion(y_pred, label_train)\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()  \n",
    "\n",
    "# Finally, the learned FMs\n",
    "FM_learned = (net.chi_nn_vars(net.vars).cpu()).detach().numpy()\n",
    "print('\\n\\nLearned FMs:')\n",
    "print('FM1 = ', FM_learned[:,0])\n",
    "# print('FM2 = ',FM_learned[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61dc2b92",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fusion_train_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c011577c4f16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Create a synthetic dataset via random sampling from a normal distribution with mean =-1 and std=2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfusion_train_2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Let's specify the FMs  (There will be N_out number of FMs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fusion_train_2' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
