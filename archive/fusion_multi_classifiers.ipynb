{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2911dfaf",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from itertools import permutations, combinations\n",
    "import os\n",
    "\n",
    "from cvxopt import solvers, matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, models,datasets\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e01387b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def multi_classifier_output(data_loader, list_classifiers, label_idx_in_imagenet, soft_max):\n",
    "#     num_classifiers = len(list_classifiers)\n",
    "#     num_classes = len(label_idx_in_imagenet)\n",
    "    \n",
    "    output_all_multi_classifier = []\n",
    "    labels_all = []\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        print(i)\n",
    "        if i == 3:\n",
    "            break\n",
    "        output_list = []\n",
    "        for j, classifier in enumerate(list_classifiers):\n",
    "            print(j)\n",
    "            output = classifier(images)\n",
    "            output_simple = output[:, label_idx_in_imagenet]\n",
    "            output_simple_sm = soft_max(output_simple)\n",
    "            output_list.append(output_simple_sm)\n",
    "        output_batch_multi_classifier = torch.stack(output_list, dim=2)\n",
    "        output_all_multi_classifier.append(output_batch_multi_classifier)\n",
    "        labels_all.append(labels)\n",
    "    output_all_multi_classifier = torch.cat(output_all_multi_classifier, dim=0)\n",
    "    labels_all = torch.cat(labels_all, dim=0)\n",
    "#     labels_al_one_hot = make_one_hot(labels_all, 3)\n",
    "    \n",
    "    return output_all_multi_classifier, labels_all\n",
    "\n",
    "\n",
    "def cal_chi(fm, x):\n",
    "    \"\"\"\n",
    "    Calculates ChI with given fuzzy measure and input\n",
    "    \n",
    "    :param fm: Fuzzy measure\n",
    "    :param x: Input\n",
    "    :return: Single value Chi output\n",
    "    \"\"\"\n",
    "    pi_i = np.argsort(-x) + 1 # Arg sort of input, with the smallest index9 being 1\n",
    "    ch = x[pi_i[0] - 1] * (fm[str(pi_i[:1])])\n",
    "    for i in range(1, len(x)):\n",
    "        latt_pti = np.sort(pi_i[:i+1])\n",
    "        latt_ptimin1 = np.sort(pi_i[:i])\n",
    "        ch = ch + x[pi_i[i] - 1] * (fm[str(latt_pti)] - fm[str(latt_ptimin1)])\n",
    "    return ch\n",
    "\n",
    "\n",
    "def get_cal_chi(fm):\n",
    "    return lambda x: cal_chi(fm, x)\n",
    "\n",
    "\n",
    "def calculate_accuracy(target, output):\n",
    "    acc = np.sum(target == output.round()) / len(target)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def make_one_hot(labels, num_classes):\n",
    "    one_hot = torch.zeros(len(labels), num_classes)\n",
    "    for i, label in enumerate(labels):\n",
    "        one_hot[i, label] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb5ad3d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ChIQP\n",
    "\n",
    "# Silencing solvers.qp\n",
    "from contextlib import redirect_stdout\n",
    "from io import StringIO\n",
    "class NullIO(StringIO):\n",
    "    def write(self, txt):\n",
    "        pass\n",
    "\n",
    "\n",
    "def silent(fn):\n",
    "    \"\"\"Decorator to silence functions.\"\"\"\n",
    "    def silent_fn(*args, **kwargs):\n",
    "        with redirect_stdout(NullIO()):\n",
    "            return fn(*args, **kwargs)\n",
    "    return silent_fn\n",
    "\n",
    "\n",
    "class Choquet_Integral_QP:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Instantiation of a ChoquetIntegral.\n",
    "           This sets up the ChI. It doesn't take any input parameters\n",
    "           because you may want to use pass your own values in(as opposed\n",
    "           to learning from data). To instatiate, use\n",
    "           chi = ChoquetIntegral.ChoquetIntegral()\n",
    "        \"\"\"\n",
    "        self.trainSamples, self.trainLabels = [], []\n",
    "        self.testSamples, self.testLabels = [], []\n",
    "        self.N, self.numberConstraints, self.M = 0, 0, 0\n",
    "        self.g = 0\n",
    "        self.fm = []\n",
    "        self.type = []\n",
    "\n",
    "\n",
    "    def train_chi(self, x1, l1):\n",
    "        \"\"\"\n",
    "        This trains this instance of your ChoquetIntegral w.r.t x1 and l1.\n",
    "        :param x1: These are the training samples of size N x M(inputs x number of samples)\n",
    "        :param l1: These are the training labels of size 1 x M(label per sample)\n",
    "        \"\"\"\n",
    "        self.type = 'quad'\n",
    "        self.trainSamples = x1\n",
    "        self.trainLabels = l1\n",
    "        self.N = self.trainSamples.shape[0]\n",
    "        self.M = self.trainSamples.shape[1]\n",
    "#         print(\"Number Inputs : \", self.N, \"; Number Samples : \", self.M)\n",
    "        self.fm = self.produce_lattice()\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "    def chi_quad(self, x2):\n",
    "        \"\"\"\n",
    "        This will produce an output for this instance of the ChI\n",
    "        This will use the learned(or specified) Choquet integral to\n",
    "        produce an output w.r.t. to the new input.\n",
    "        :param x2: testing sample\n",
    "        :return: output of the choquet integral.\n",
    "        \"\"\"\n",
    "        if self.type == 'quad':\n",
    "            n = len(x2)\n",
    "            pi_i = np.argsort(x2)[::-1][:n] + 1\n",
    "            ch = x2[pi_i[0] - 1] * (self.fm[str(pi_i[:1])])\n",
    "            for i in range(1, n):\n",
    "                latt_pti = np.sort(pi_i[:i + 1])\n",
    "                latt_ptimin1 = np.sort(pi_i[:i])\n",
    "                ch = ch + x2[pi_i[i] - 1] * (self.fm[str(latt_pti)] - self.fm[str(latt_ptimin1)])\n",
    "            return ch\n",
    "        else:\n",
    "            print(\"If using sugeno measure, you need to use chi_sugeno.\")\n",
    "\n",
    "\n",
    "    def produce_lattice(self):\n",
    "        \"\"\"\n",
    "            This method builds is where the lattice(or FM variables) will be learned.\n",
    "            The FM values can be found via a quadratic program, which is used here\n",
    "            after setting up constraint matrices. Refer to papers for complete overview.\n",
    "        :return: Lattice, the learned FM variables.\n",
    "        \"\"\"\n",
    "\n",
    "        fm_len = 2 ** self.N - 1  # nc\n",
    "        E = np.zeros((fm_len, fm_len))  # D\n",
    "        L = np.zeros(fm_len)  # f\n",
    "        index_keys = self.get_keys_index()\n",
    "        for i in range(0, self.M):  # it's going through one sample at a time.\n",
    "            l = self.trainLabels[i]  # this is the labels\n",
    "            fm_coeff = self.get_fm_class_img_coeff(index_keys, self.trainSamples[:, i], fm_len)  # this is Hdiff\n",
    "            # print(fm_coeff)\n",
    "#             print(L, l, fm_coeff)\n",
    "            L = L + (-2) * l * fm_coeff\n",
    "            E = E + np.matmul(fm_coeff.reshape((fm_len, 1)), fm_coeff.reshape((1, fm_len)))\n",
    "\n",
    "        G, h, A, b = self.build_constraint_matrices(index_keys, fm_len)\n",
    "        solvers_qp = silent(solvers.qp)\n",
    "        sol = solvers_qp(matrix(2 * E, tc='d'), matrix(L.T, tc='d'), matrix(G, tc='d'), matrix(h, tc='d'),\n",
    "                         matrix(A, tc='d'), matrix(b, tc='d'))\n",
    "        g = sol['x']\n",
    "        Lattice = {}\n",
    "        for key in index_keys.keys():\n",
    "            Lattice[key] = g[index_keys[key]]\n",
    "        return Lattice\n",
    "\n",
    "\n",
    "    def build_constraint_matrices(self, index_keys, fm_len):\n",
    "        \"\"\"\n",
    "        This method builds the necessary constraint matrices.\n",
    "        :param index_keys: map to reference lattice components\n",
    "        :param fm_len: length of the fuzzy measure\n",
    "        :return: the constraint matrices\n",
    "        \"\"\"\n",
    "\n",
    "        vls = np.arange(1, self.N + 1)\n",
    "        line = np.zeros(fm_len)\n",
    "        G = line\n",
    "        line[index_keys[str(np.array([1]))]] = -1.\n",
    "        h = np.array([0])\n",
    "        for i in range(2, self.N + 1):\n",
    "            line = np.zeros(fm_len)\n",
    "            line[index_keys[str(np.array([i]))]] = -1.\n",
    "            G = np.vstack((G, line))\n",
    "            h = np.vstack((h, np.array([0])))\n",
    "        for i in range(2, self.N + 1):\n",
    "            parent = np.array(list(combinations(vls, i)))\n",
    "            for latt_pt in parent:\n",
    "                for j in range(len(latt_pt) - 1, len(latt_pt)):\n",
    "                    children = np.array(list(combinations(latt_pt, j)))\n",
    "                    for latt_ch in children:\n",
    "                        line = np.zeros(fm_len)\n",
    "                        line[index_keys[str(latt_ch)]] = 1.\n",
    "                        line[index_keys[str(latt_pt)]] = -1.\n",
    "                        G = np.vstack((G, line))\n",
    "                        h = np.vstack((h, np.array([0])))\n",
    "\n",
    "        line = np.zeros(fm_len)\n",
    "        line[index_keys[str(vls)]] = 1.\n",
    "        G = np.vstack((G, line))\n",
    "        h = np.vstack((h, np.array([1])))\n",
    "\n",
    "        # equality constraints\n",
    "        A = np.zeros((1, fm_len))\n",
    "        A[0, -1] = 1\n",
    "        b = np.array([1]);\n",
    "\n",
    "        return G, h, A, b\n",
    "\n",
    "\n",
    "    def get_fm_class_img_coeff(self, Lattice, h, fm_len):  # Lattice is FM_name_and_index, h is the samples, fm_len\n",
    "        \"\"\"\n",
    "        This creates a FM map with the name as the key and the index as the value\n",
    "        :param Lattice: dictionary with FM\n",
    "        :param h: sample\n",
    "        :param fm_len: fm length\n",
    "        :return: the fm_coeff\n",
    "        \"\"\"\n",
    "\n",
    "        n = len(h)  # len(h) is the number of the samples\n",
    "        fm_coeff = np.zeros(fm_len)\n",
    "        pi_i = np.argsort(-h) + 1\n",
    "        for i in range(1, n):\n",
    "            fm_coeff[Lattice[str(np.sort(pi_i[:i]))]] = h[pi_i[i - 1] - 1] - h[pi_i[i] - 1]\n",
    "        fm_coeff[Lattice[str(np.sort(pi_i[:n]))]] = h[pi_i[n - 1] - 1]\n",
    "        np.matmul(fm_coeff, np.transpose(fm_coeff))\n",
    "        return fm_coeff\n",
    "\n",
    "\n",
    "    def get_keys_index(self):\n",
    "        \"\"\"\n",
    "        Sets up a dictionary for referencing FM.\n",
    "        :return: The keys to the dictionary\n",
    "        \"\"\"\n",
    "\n",
    "        vls = np.arange(1, self.N + 1)\n",
    "        count = 0\n",
    "        Lattice = {}\n",
    "        for i in range(0, self.N):\n",
    "            Lattice[str(np.array([vls[i]]))] = count\n",
    "            count = count + 1\n",
    "        for i in range(2, self.N + 1):\n",
    "            A = np.array(list(combinations(vls, i)))\n",
    "            for latt_pt in A:\n",
    "                Lattice[str(latt_pt)] = count\n",
    "                count = count + 1\n",
    "        return Lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "122536f0",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Models, Dataset & Dataloader\n",
    "\n",
    "# Download pretrained models on imagenet\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "squeezenet = models.squeezenet1_0(pretrained=True)\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "densenet = models.densenet161(pretrained=True)\n",
    "inception = models.inception_v3(pretrained=True)\n",
    "googlenet = models.googlenet(pretrained=True)\n",
    "shufflenet = models.shufflenet_v2_x1_0(pretrained=True)\n",
    "mobilenet_v2 = models.mobilenet_v2(pretrained=True)\n",
    "mobilenet_v3_large = models.mobilenet_v3_large(pretrained=True)\n",
    "mobilenet_v3_small = models.mobilenet_v3_small(pretrained=True)\n",
    "resnext50_32x4d = models.resnext50_32x4d(pretrained=True)\n",
    "wide_resnet50_2 = models.wide_resnet50_2(pretrained=True)\n",
    "mnasnet = models.mnasnet1_0(pretrained=True)\n",
    "\n",
    "# Dataset & Dataloader\n",
    "batch_size = 100\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize(256),\n",
    "     transforms.CenterCrop(224),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225])\n",
    "])  \n",
    "img_path = r'./data/LJ-Test'\n",
    "\n",
    "train_set = datasets.ImageFolder(os.path.join(img_path, 'train'), transform)\n",
    "test_set = datasets.ImageFolder(os.path.join(img_path, 'val'), transform)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "train_iter = iter(train_loader)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "test_iter = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0338ccfa",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/nn/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1623459044803/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Get train&test model output from multiple classifiers\n",
    "\n",
    "list_classifiers = [mobilenet_v3_small, mobilenet_v3_large, squeezenet, ]\n",
    "label_idx_in_imagenet = [217, 574, 701]\n",
    "soft_max = torch.nn.Softmax(dim=1)\n",
    "\n",
    "train_output_all_multi_classifier, train_labels_all = multi_classifier_output(train_loader, list_classifiers, label_idx_in_imagenet, soft_max)\n",
    "test_output_all_multi_classifier, test_labels_all = multi_classifier_output(test_loader, list_classifiers, label_idx_in_imagenet, soft_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c56c838d",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train ChIQP\n",
    "train_labels_all_one_hot = make_one_hot(train_labels_all, 3)\n",
    "\n",
    "if isinstance(train_output_all_multi_classifier, (torch.Tensor, torch.FloatTensor)):\n",
    "    train_output_all_multi_classifier = train_output_all_multi_classifier.detach().numpy()\n",
    "if isinstance(train_labels_all, (torch.Tensor, torch.FloatTensor)):\n",
    "    train_labels_all = train_labels_all.detach().numpy()\n",
    "if isinstance(train_labels_all_one_hot, (torch.Tensor, torch.FloatTensor)):\n",
    "    train_labels_all_one_hot = train_labels_all_one_hot.detach().numpy()\n",
    "\n",
    "\n",
    "chiqps = []\n",
    "for i in range(len(label_idx_in_imagenet)):\n",
    "    # Initialize ChIQP\n",
    "    chiqp = Choquet_Integral_QP()\n",
    "    # Train \n",
    "    chiqp.train_chi(train_output_all_multi_classifier[:, i, :].transpose(), train_labels_all_one_hot[:, i])\n",
    "    chiqps.append(chiqp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20e5f2e2",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of single classifier 0 = 0.99\n",
      "Accuracy of single classifier 1 = 0.9966666666666667\n",
      "Accuracy of single classifier 2 = 0.9933333333333333\n",
      "Fused accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy comparison\n",
    "\n",
    "# Single model accuracies\n",
    "test_labels_all_one_hot = make_one_hot(test_labels_all, 3)\n",
    "if isinstance(test_output_all_multi_classifier, (torch.Tensor, torch.FloatTensor)):\n",
    "    test_output_all_multi_classifier = test_output_all_multi_classifier.detach().numpy()\n",
    "if isinstance(test_labels_all, (torch.Tensor, torch.FloatTensor)):\n",
    "    test_labels_all = test_labels_all.detach().numpy()\n",
    "if isinstance(test_labels_all_one_hot, (torch.Tensor, torch.FloatTensor)):\n",
    "    test_labels_all_one_hot = test_labels_all_one_hot.detach().numpy()\n",
    "    \n",
    "\n",
    "\n",
    "accuracies = []\n",
    "for i in range(len(list_classifiers)):\n",
    "    test_output_all = test_output_all_multi_classifier[:, :, i]\n",
    "    test_predict = np.argmax(test_output_all, axis=1)\n",
    "    acc = calculate_accuracy(target=test_labels_all, output=test_predict)\n",
    "    accuracies.append(acc)\n",
    "    print('Accuracy of single classifier', i, '=', acc)\n",
    "    \n",
    "    \n",
    "# Test ChIQP, Fused model accuracy\n",
    "fusions = []\n",
    "for i in range(len(label_idx_in_imagenet)):\n",
    "    chiqp = chiqps[i]\n",
    "    fm = chiqp.fm\n",
    "    fusion = np.apply_along_axis(get_cal_chi(fm), 1, test_output_all_multi_classifier[:, i, :])\n",
    "    fusions.append(fusion)\n",
    "\n",
    "fused_output_one_hot = np.stack(fusions, 1)\n",
    "fused_output = np.argmax(fused_output_one_hot, axis=1)\n",
    "\n",
    "acc = calculate_accuracy(target=test_labels_all, output=fused_output)\n",
    "print('Fused accuracy =', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2088dd08",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macOS\n",
      "Interactive plot activated\n"
     ]
    }
   ],
   "source": [
    "# Unsupervised\n",
    "\n",
    "# Imports\n",
    "\n",
    "import itertools\n",
    "from itertools import permutations\n",
    "from math import tanh\n",
    "import os\n",
    "import pickle\n",
    "import platform\n",
    "import random\n",
    "from tkinter import Tk\n",
    "\n",
    "from cvxopt import solvers, matrix\n",
    "import math\n",
    "from matplotlib import animation\n",
    "from  matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, models,datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Extend width of Jupyter Notebook Cell to the size of browser\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# OS related settings\n",
    "if platform.system() == 'Windows':\n",
    "    print('Windows')\n",
    "#     %matplotlib tk\n",
    "    %matplotlib qt\n",
    "elif platform.system() == 'Darwin':\n",
    "    print('macOS')\n",
    "    Tk().withdraw()\n",
    "    %matplotlib osx\n",
    "elif platform == 'linux' or platform == 'linux2':\n",
    "    print('Linux')\n",
    "# This line of \"print\" must exist right after %matplotlib command, otherwise JN will hang on the first import statement after this.\n",
    "print('Interactive plot activated')\n",
    "\n",
    "\n",
    "\n",
    "# Functions\n",
    "\n",
    "\n",
    "def cal_chi(fm, x):\n",
    "    \"\"\"\n",
    "    Calculates ChI with given fuzzy measure and input\n",
    "    \n",
    "    :param fm: Fuzzy measure\n",
    "    :param x: Input\n",
    "    :return: Single value Chi output\n",
    "    \"\"\"\n",
    "    pi_i = np.argsort(-x) + 1 # Arg sort of input, with the smallest index9 being 1\n",
    "    ch = x[pi_i[0] - 1] * (fm[str(pi_i[:1])])\n",
    "    for i in range(1, len(x)):\n",
    "        latt_pti = np.sort(pi_i[:i+1])\n",
    "        latt_ptimin1 = np.sort(pi_i[:i])\n",
    "        ch = ch + x[pi_i[i] - 1] * (fm[str(latt_pti)] - fm[str(latt_ptimin1)])\n",
    "    return ch\n",
    "\n",
    "\n",
    "def get_cal_chi(fm):\n",
    "    return lambda x: cal_chi(fm, x)\n",
    "\n",
    "\n",
    "\n",
    "def get_keys_index(dim):\n",
    "    \"\"\"\n",
    "    Sets up a dictionary for referencing FM.\n",
    "    :return: The keys to the dictionary\n",
    "    \"\"\"\n",
    "    vls = np.arange(1, dim + 1)\n",
    "    Lattice = {}\n",
    "    for i in range(1, dim + 1):\n",
    "        A = np.array(list(itertools.combinations(vls, i)))\n",
    "        for latt_pt in A:\n",
    "            Lattice[str(latt_pt)] = 1\n",
    "    return Lattice\n",
    "\n",
    "\n",
    "def get_min_fm_target(dim):\n",
    "    fm = get_keys_index(dim)\n",
    "    for key in fm.keys():\n",
    "        if len(key.split()) != dim:\n",
    "            fm[key] = 0\n",
    "        else:\n",
    "            fm[key] = 1\n",
    "    return fm\n",
    "    \n",
    "    \n",
    "def get_max_fm_target(dim):\n",
    "    fm = get_keys_index(dim)\n",
    "    return fm\n",
    "\n",
    "\n",
    "def get_mean_fm_target(dim):\n",
    "    fm = get_keys_index(dim)\n",
    "    for key in fm.keys():\n",
    "        fm[key] = len(key.split()) / dim\n",
    "    return fm\n",
    "\n",
    "\n",
    "def get_gmean_fm_target(dim):\n",
    "    fm = get_mean_fm_target(dim)\n",
    "    return fm\n",
    "\n",
    "\n",
    "\n",
    "def create_synthetic_data(num_samples=100, accuracies=[0.9, 0.6, 0.5]):\n",
    "    label = np.random.randint(0, 2, num_samples)\n",
    "\n",
    "    flip_ind = []\n",
    "    for acc in accuracies:\n",
    "        flip_ind.append(np.random.choice(range(num_samples), round((1-acc)*num_samples), replace=False))\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    for ind in flip_ind:\n",
    "        output_bin = np.copy(label)\n",
    "        output_bin[ind] = 1 - output_bin[ind]\n",
    "        output = np.asarray([(random.random()+1)/2 if o_b == 1 else random.random()/2 for o_b in output_bin])\n",
    "        \n",
    "        outputs.append(output)\n",
    "    outputs = np.asarray(outputs)\n",
    "    \n",
    "    return(label, outputs)\n",
    "    \n",
    "\n",
    "def test_accuracy(target, output):\n",
    "    acc = np.sum(target == output.round()) / len(target)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cdfd9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[1]': 0.99, '[2]': 0.9966666666666667, '[3]': 0.9933333333333333, '[1 2]': 1.0, '[1 3]': 0.9966666666666667, '[2 3]': 1.0, '[1 2 3]': 1.0}\n",
      "{'[1]': 0.2797478770780614, '[2]': 0.38691878958860687, '[3]': 0.3333333333333333, '[1 2]': 0.685109351754124, '[1 3]': 0.630227486052148, '[2 3]': 0.685109351754124, '[1 2 3]': 1.0}\n",
      "Accuracy of single classifier 0 = 0.99\n",
      "Accuracy of single classifier 1 = 0.9966666666666667\n",
      "Accuracy of single classifier 2 = 0.9933333333333333\n",
      "Fused accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "dim = len(list_classifiers)\n",
    "\n",
    "pA = get_keys_index(dim)\n",
    "\n",
    "\n",
    "for key in pA.keys():\n",
    "    key_int = np.asarray(key[1:-1].split()).astype(int) - 1\n",
    "    output_coalition = np.argmax(np.mean(test_output_all_multi_classifier[:, :, key_int], 2), 1)\n",
    "    acc_coalition = calculate_accuracy(test_labels_all, output_coalition)\n",
    "    pA[key] = acc_coalition\n",
    "    \n",
    "print(pA)\n",
    "\n",
    "fm = get_mean_fm_target(dim)\n",
    "\n",
    "for i in range(len(list(fm.keys())[-1].split())):\n",
    "    for key in fm.keys():\n",
    "        if len(key.split()) == i:\n",
    "            pA_i_cardinality = [pA[k] for k in pA.keys() if len(k.split())==len(key.split())]\n",
    "            fm[key] = fm[key] + tanh(100*(pA[key]-np.mean(pA_i_cardinality))) / (2*len(pA_i_cardinality))\n",
    "\n",
    "print(fm)\n",
    "\n",
    "\n",
    "# Test Unsup fm, Fused model accuracy\n",
    "accuracies = []\n",
    "for i in range(len(list_classifiers)):\n",
    "    test_output_all = test_output_all_multi_classifier[:, :, i]\n",
    "    test_predict = np.argmax(test_output_all, axis=1)\n",
    "    acc = calculate_accuracy(target=test_labels_all, output=test_predict)\n",
    "    accuracies.append(acc)\n",
    "    print('Accuracy of single classifier', i, '=', acc)\n",
    "\n",
    "\n",
    "\n",
    "fusions = []\n",
    "for i in range(len(label_idx_in_imagenet)):\n",
    "    fusion = np.apply_along_axis(get_cal_chi(fm), 1, test_output_all_multi_classifier[:, i, :])\n",
    "    fusions.append(fusion)\n",
    "\n",
    "fused_output_one_hot = np.stack(fusions, 1)\n",
    "fused_output = np.argmax(fused_output_one_hot, axis=1)\n",
    "\n",
    "acc = calculate_accuracy(target=test_labels_all, output=fused_output)\n",
    "print('Fused accuracy =', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
