{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba2dffb",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macOS\n",
      "Interactive plot activated\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import itertools\n",
    "from itertools import permutations\n",
    "import os\n",
    "import platform\n",
    "import random\n",
    "from tkinter import Tk\n",
    "\n",
    "from cvxopt import solvers, matrix\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, models,datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Extend width of Jupyter Notebook Cell to the size of browser\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# OS related settings\n",
    "if platform.system() == 'Windows':\n",
    "    print('Windows')\n",
    "#     %matplotlib tk\n",
    "    %matplotlib qt\n",
    "elif platform.system() == 'Darwin':\n",
    "    print('macOS')\n",
    "    Tk().withdraw()\n",
    "    %matplotlib osx\n",
    "elif platform == 'linux' or platform == 'linux2':\n",
    "    print('Linux')\n",
    "# This line of \"print\" must exist right after %matplotlib command, otherwise JN will hang on the first import statement after this.\n",
    "print('Interactive plot activated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6636ac83",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ChIQP\n",
    "\n",
    "# Silencing solvers.qp\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "from io import StringIO\n",
    "class NullIO(StringIO):\n",
    "    def write(self, txt):\n",
    "        pass\n",
    "\n",
    "\n",
    "def silent(fn):\n",
    "    \"\"\"Decorator to silence functions.\"\"\"\n",
    "    def silent_fn(*args, **kwargs):\n",
    "        with redirect_stdout(NullIO()):\n",
    "            return fn(*args, **kwargs)\n",
    "    return silent_fn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ChoquetIntegral:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Instantiation of a ChoquetIntegral.\n",
    "           This sets up the ChI. It doesn't take any input parameters\n",
    "           because you may want to use pass your own values in(as opposed\n",
    "           to learning from data). To instatiate, use\n",
    "           chi = ChoquetIntegral.ChoquetIntegral()\n",
    "        \"\"\"\n",
    "        self.trainSamples, self.trainLabels = [], []\n",
    "        self.testSamples, self.testLabels = [], []\n",
    "        self.N, self.numberConstraints, self.M = 0, 0, 0\n",
    "        self.g = 0\n",
    "        self.fm = []\n",
    "        self.type = []\n",
    "\n",
    "\n",
    "    def train_chi(self, x1, l1):\n",
    "        \"\"\"\n",
    "        This trains this instance of your ChoquetIntegral w.r.t x1 and l1.\n",
    "        :param x1: These are the training samples of size N x M(inputs x number of samples)\n",
    "        :param l1: These are the training labels of size 1 x M(label per sample)\n",
    "        \"\"\"\n",
    "        self.type = 'quad'\n",
    "        self.trainSamples = x1\n",
    "        self.trainLabels = l1\n",
    "        self.N = self.trainSamples.shape[0]\n",
    "        self.M = self.trainSamples.shape[1]\n",
    "#         print(\"Number Inputs : \", self.N, \"; Number Samples : \", self.M)\n",
    "        self.fm = self.produce_lattice()\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "    def chi_quad(self, x2):\n",
    "        \"\"\"\n",
    "        This will produce an output for this instance of the ChI\n",
    "        This will use the learned(or specified) Choquet integral to\n",
    "        produce an output w.r.t. to the new input.\n",
    "        :param x2: testing sample\n",
    "        :return: output of the choquet integral.\n",
    "        \"\"\"\n",
    "        if self.type == 'quad':\n",
    "            n = len(x2)\n",
    "            pi_i = np.argsort(x2)[::-1][:n] + 1\n",
    "            ch = x2[pi_i[0] - 1] * (self.fm[str(pi_i[:1])])\n",
    "            for i in range(1, n):\n",
    "                latt_pti = np.sort(pi_i[:i + 1])\n",
    "                latt_ptimin1 = np.sort(pi_i[:i])\n",
    "                ch = ch + x2[pi_i[i] - 1] * (self.fm[str(latt_pti)] - self.fm[str(latt_ptimin1)])\n",
    "            return ch\n",
    "        else:\n",
    "            print(\"If using sugeno measure, you need to use chi_sugeno.\")\n",
    "\n",
    "\n",
    "    def produce_lattice(self):\n",
    "        \"\"\"\n",
    "            This method builds is where the lattice(or FM variables) will be learned.\n",
    "            The FM values can be found via a quadratic program, which is used here\n",
    "            after setting up constraint matrices. Refer to papers for complete overview.\n",
    "        :return: Lattice, the learned FM variables.\n",
    "        \"\"\"\n",
    "\n",
    "        fm_len = 2 ** self.N - 1  # nc\n",
    "        E = np.zeros((fm_len, fm_len))  # D\n",
    "        L = np.zeros(fm_len)  # f\n",
    "        index_keys = self.get_keys_index()\n",
    "        for i in range(0, self.M):  # it's going through one sample at a time.\n",
    "            l = self.trainLabels[i]  # this is the labels\n",
    "            fm_coeff = self.get_fm_class_img_coeff(index_keys, self.trainSamples[:, i], fm_len)  # this is Hdiff\n",
    "            # print(fm_coeff)\n",
    "            L = L + (-2) * l * fm_coeff\n",
    "            E = E + np.matmul(fm_coeff.reshape((fm_len, 1)), fm_coeff.reshape((1, fm_len)))\n",
    "\n",
    "        G, h, A, b = self.build_constraint_matrices(index_keys, fm_len)\n",
    "        solvers_qp = silent(solvers.qp)\n",
    "        sol = solvers_qp(matrix(2 * E, tc='d'), matrix(L.T, tc='d'), matrix(G, tc='d'), matrix(h, tc='d'),\n",
    "                         matrix(A, tc='d'), matrix(b, tc='d'))\n",
    "        g = sol['x']\n",
    "        Lattice = {}\n",
    "        for key in index_keys.keys():\n",
    "            Lattice[key] = g[index_keys[key]]\n",
    "        return Lattice\n",
    "\n",
    "\n",
    "    def build_constraint_matrices(self, index_keys, fm_len):\n",
    "        \"\"\"\n",
    "        This method builds the necessary constraint matrices.\n",
    "        :param index_keys: map to reference lattice components\n",
    "        :param fm_len: length of the fuzzy measure\n",
    "        :return: the constraint matrices\n",
    "        \"\"\"\n",
    "\n",
    "        vls = np.arange(1, self.N + 1)\n",
    "        line = np.zeros(fm_len)\n",
    "        G = line\n",
    "        line[index_keys[str(np.array([1]))]] = -1.\n",
    "        h = np.array([0])\n",
    "        for i in range(2, self.N + 1):\n",
    "            line = np.zeros(fm_len)\n",
    "            line[index_keys[str(np.array([i]))]] = -1.\n",
    "            G = np.vstack((G, line))\n",
    "            h = np.vstack((h, np.array([0])))\n",
    "        for i in range(2, self.N + 1):\n",
    "            parent = np.array(list(itertools.combinations(vls, i)))\n",
    "            for latt_pt in parent:\n",
    "                for j in range(len(latt_pt) - 1, len(latt_pt)):\n",
    "                    children = np.array(list(itertools.combinations(latt_pt, j)))\n",
    "                    for latt_ch in children:\n",
    "                        line = np.zeros(fm_len)\n",
    "                        line[index_keys[str(latt_ch)]] = 1.\n",
    "                        line[index_keys[str(latt_pt)]] = -1.\n",
    "                        G = np.vstack((G, line))\n",
    "                        h = np.vstack((h, np.array([0])))\n",
    "\n",
    "        line = np.zeros(fm_len)\n",
    "        line[index_keys[str(vls)]] = 1.\n",
    "        G = np.vstack((G, line))\n",
    "        h = np.vstack((h, np.array([1])))\n",
    "\n",
    "        # equality constraints\n",
    "        A = np.zeros((1, fm_len))\n",
    "        A[0, -1] = 1\n",
    "        b = np.array([1]);\n",
    "\n",
    "        return G, h, A, b\n",
    "\n",
    "\n",
    "    def get_fm_class_img_coeff(self, Lattice, h, fm_len):  # Lattice is FM_name_and_index, h is the samples, fm_len\n",
    "        \"\"\"\n",
    "        This creates a FM map with the name as the key and the index as the value\n",
    "        :param Lattice: dictionary with FM\n",
    "        :param h: sample\n",
    "        :param fm_len: fm length\n",
    "        :return: the fm_coeff\n",
    "        \"\"\"\n",
    "\n",
    "        n = len(h)  # len(h) is the number of the samples\n",
    "        fm_coeff = np.zeros(fm_len)\n",
    "        pi_i = np.argsort(h)[::-1][:n] + 1\n",
    "        for i in range(1, n):\n",
    "            fm_coeff[Lattice[str(np.sort(pi_i[:i]))]] = h[pi_i[i - 1] - 1] - h[pi_i[i] - 1]\n",
    "        fm_coeff[Lattice[str(np.sort(pi_i[:n]))]] = h[pi_i[n - 1] - 1]\n",
    "        np.matmul(fm_coeff, np.transpose(fm_coeff))\n",
    "        return fm_coeff\n",
    "\n",
    "\n",
    "    def get_keys_index(self):\n",
    "        \"\"\"\n",
    "        Sets up a dictionary for referencing FM.\n",
    "        :return: The keys to the dictionary\n",
    "        \"\"\"\n",
    "\n",
    "        vls = np.arange(1, self.N + 1)\n",
    "        count = 0\n",
    "        Lattice = {}\n",
    "        for i in range(0, self.N):\n",
    "            Lattice[str(np.array([vls[i]]))] = count\n",
    "            count = count + 1\n",
    "        for i in range(2, self.N + 1):\n",
    "            A = np.array(list(itertools.combinations(vls, i)))\n",
    "            for latt_pt in A:\n",
    "                Lattice[str(latt_pt)] = count\n",
    "                count = count + 1\n",
    "        return Lattice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066a2f3d",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/120 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ready\n",
      "Train data superset size: (5, 6000)\n",
      "Test data superset size: (5, 60000)\n",
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 10/120 [02:42<29:36, 16.15s/it]"
     ]
    }
   ],
   "source": [
    "# All in one\n",
    "\n",
    "\n",
    "# Parameters\n",
    "num_epoch = 100\n",
    "dim_list = list(range(5, 6))\n",
    "num_per_perm_train = 10 # Every permutation gets the same number of train/test data samples\n",
    "num_per_perm_test = 100 # Every permutation gets the same number of train/test data samples\n",
    "eva_func_num = 4\n",
    "superset_factor = 5\n",
    "\n",
    "SSEs_avg_list = [] # Avg SSE with seen data of every dim\n",
    "SSEs_c_avg_list = [] # Avg SSE with unseen data of every dim\n",
    "\n",
    "# Experiment for dim = 3 to 8\n",
    "for dim in dim_list:\n",
    "    \n",
    "    # Every permutation gets the same number of train/test data samples,\n",
    "    # To ensure that, calculate the number of data needed in total, \n",
    "    # and generate a dataset that is multiple times bigger.\n",
    "    num_train = math.factorial(dim) * num_per_perm_train\n",
    "    num_test = math.factorial(dim) * num_per_perm_test\n",
    "    # Create superset\n",
    "    train_data_superset = np.random.rand(dim, num_train*superset_factor)\n",
    "    test_data_superset = np.random.rand(dim, num_test*superset_factor)\n",
    "    # Get permutation of each data sample\n",
    "    train_data_perms = np.argsort(train_data_superset, 0)\n",
    "    test_data_perms = np.argsort(test_data_superset, 0)\n",
    "    # N! possible permutations\n",
    "    all_perms = list(permutations(list(range(dim))))\n",
    "    # Group data sample according to its permutation\n",
    "    train_data_superset_by_perm = []\n",
    "    test_data_superset_by_perm = []\n",
    "    for i, current_perm in enumerate(all_perms):\n",
    "        # Get index of data sample of certain permutation and save to list\n",
    "        temp = np.where(train_data_perms[0, :]==current_perm[0])\n",
    "        for j, idx in enumerate(current_perm):\n",
    "            temp = np.intersect1d(temp, np.where(train_data_perms[j, :]==idx))\n",
    "        if temp.size < num_per_perm_train:\n",
    "            print('Current permutation doesn\\'t have sufficient number of samples. Please regenerate!')\n",
    "            exit()\n",
    "        train_data_superset_by_perm.append(temp)\n",
    "        \n",
    "        # Get index of data sample of certain permutation and save to list\n",
    "        temp = np.where(test_data_perms[0, :]==current_perm[0])\n",
    "        for j, idx in enumerate(current_perm):\n",
    "            temp = np.intersect1d(temp, np.where(test_data_perms[j, :]==idx))\n",
    "        if temp.size < num_per_perm_test:\n",
    "            print('Current permutation doesn\\'t have sufficient number of samples. Please regenerate!')\n",
    "            exit()\n",
    "        test_data_superset_by_perm.append(temp)\n",
    "    print('Data ready')\n",
    "    print('Train data superset size:', train_data_superset.shape)\n",
    "    print('Test data superset size:', test_data_superset.shape)\n",
    "\n",
    "\n",
    "\n",
    "    SSEs_sum = np.zeros((len(all_perms), eva_func_num)) # Sum of SSE with seen data of certain dim\n",
    "    SSEs_c_sum = np.zeros((len(all_perms)-1, eva_func_num)) # Sum of SSE with unseen data of certain dim\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        print('Epoch', epoch)\n",
    "        \n",
    "        # Every permutation gets the same number of train/test data samples,\n",
    "        # Data is randomly pull from superset each epoch\n",
    "        train_data_by_perm = []\n",
    "        test_data_by_perm = []\n",
    "        for i in range(len(all_perms)):\n",
    "            temp = train_data_superset_by_perm[i]\n",
    "            random.shuffle(temp)\n",
    "            train_data_by_perm.append(temp[0:num_per_perm_train])\n",
    "\n",
    "            temp = test_data_superset_by_perm[i]\n",
    "            random.shuffle(temp)\n",
    "            test_data_by_perm.append(temp[0:num_per_perm_test])\n",
    "\n",
    "        SSEs = np.zeros((len(all_perms), eva_func_num))\n",
    "        SSEs_c = np.zeros((len(all_perms)-1, eva_func_num))\n",
    "        \n",
    "        # Train group limit\n",
    "        train_group_num_limit = math.factorial(5)\n",
    "        step = 1\n",
    "        if len(all_perms) > train_group_num_limit:\n",
    "            step = int(len(all_perms) / train_group_num_limit)\n",
    "        for i in tqdm(range(step-1, len(all_perms), step)):\n",
    "\n",
    "            train_idx = np.concatenate(train_data_by_perm[0:i+1])\n",
    "            test_idx = np.concatenate(test_data_by_perm[0:i+1])\n",
    "            \n",
    "            train_d = train_data_superset[:, train_idx]\n",
    "            test_d = test_data_superset[:, test_idx]\n",
    "\n",
    "            train_label_min = np.amin(train_d, 0)\n",
    "            train_label_max = np.amax(train_d, 0)\n",
    "            train_label_mean = np.mean(train_d, 0)\n",
    "            train_label_gmean = np.cbrt(np.prod(train_d, 0))\n",
    "\n",
    "            test_label_min = np.amin(test_d, 0)\n",
    "            test_label_max = np.amax(test_d, 0)\n",
    "            test_label_mean = np.mean(test_d, 0)\n",
    "            test_label_gmean = np.cbrt(np.prod(test_d, 0))\n",
    "\n",
    "            if i < len(all_perms)-1:\n",
    "                test_idx_c = np.concatenate(test_data_by_perm[i:-1])\n",
    "                test_d_c = test_data_superset[:, test_idx_c]\n",
    "\n",
    "                test_label_min_c = np.amin(test_d_c, 0)\n",
    "                test_label_max_c = np.amax(test_d_c, 0)\n",
    "                test_label_mean_c = np.mean(test_d_c, 0)\n",
    "                test_label_gmean_c = np.cbrt(np.prod(test_d_c, 0))\n",
    "\n",
    "\n",
    "            chi = ChoquetIntegral()\n",
    "            chi.train_chi(train_d, train_label_min)\n",
    "            SSE = 0\n",
    "            for j in range(np.size(test_d, 1)):\n",
    "                chi_min_test = chi.chi_quad(test_d[:, j])\n",
    "                SSE += (chi_min_test - test_label_min[j]) ** 2\n",
    "            SSEs[i, 0] = SSE / np.size(test_d)\n",
    "    #         print('\\nChi min', chi.fm)\n",
    "    #         print('\\nSSE', SSE)\n",
    "            if i < len(all_perms)-1:\n",
    "                SSE_c = 0\n",
    "                for j in range(np.size(test_d_c, 1)):\n",
    "                    chi_min_test_c = chi.chi_quad(test_d_c[:, j])\n",
    "                    SSE_c += (chi_min_test_c - test_label_min_c[j]) ** 2\n",
    "                SSEs_c[i, 0] = SSE_c / np.size(test_d_c)\n",
    "    #             print('\\nUnseen data SSE', SSE_c)\n",
    "\n",
    "\n",
    "            chi = ChoquetIntegral()\n",
    "            chi.train_chi(train_d, train_label_max)\n",
    "            SSE = 0\n",
    "            for j in range(np.size(test_d, 1)):\n",
    "                chi_max_test = chi.chi_quad(test_d[:, j])\n",
    "                SSE += (chi_max_test - test_label_max[j]) ** 2\n",
    "            SSEs[i, 1] = SSE / np.size(test_d)\n",
    "    #         print('\\nChi max', chi.fm)\n",
    "    #         print('\\nSSE', SSE)\n",
    "            if i < len(all_perms)-1:\n",
    "                SSE_c = 0\n",
    "                for j in range(np.size(test_d_c, 1)):\n",
    "                    chi_max_test_c = chi.chi_quad(test_d_c[:, j])\n",
    "                    SSE_c += (chi_max_test_c - test_label_max_c[j]) ** 2\n",
    "                SSEs_c[i, 1] = SSE_c / np.size(test_d_c)\n",
    "    #             print('\\nUnseen data SSE', SSE_c)\n",
    "\n",
    "\n",
    "            chi = ChoquetIntegral()\n",
    "            chi.train_chi(train_d, train_label_mean)\n",
    "            SSE = 0\n",
    "            for j in range(np.size(test_d, 1)):\n",
    "                chi_mean_test = chi.chi_quad(test_d[:, j])\n",
    "                SSE += (chi_mean_test - test_label_mean[j]) ** 2\n",
    "            SSEs[i, 2] = SSE / np.size(test_d)\n",
    "    #         print('\\nChi mean', chi.fm)\n",
    "    #         print('\\nSSE', SSE)\n",
    "            if i < len(all_perms)-1:\n",
    "                SSE_c = 0\n",
    "                for j in range(np.size(test_d_c, 1)):\n",
    "                    chi_mean_test_c = chi.chi_quad(test_d_c[:, j])\n",
    "                    SSE_c += (chi_mean_test_c - test_label_mean_c[j]) ** 2\n",
    "                SSEs_c[i, 2] = SSE_c / np.size(test_d_c)\n",
    "    #             print('\\nUnseen data SSE', SSE_c)\n",
    "\n",
    "\n",
    "            chi = ChoquetIntegral()\n",
    "            chi.train_chi(train_d, train_label_gmean)\n",
    "            SSE = 0\n",
    "            for j in range(np.size(test_d, 1)):\n",
    "                chi_gmean_test = chi.chi_quad(test_d[:, j])\n",
    "                SSE += (chi_gmean_test - test_label_gmean[j]) ** 2\n",
    "            SSEs[i, 3] = SSE / np.size(test_d)\n",
    "    #         print('\\nChi geometric mean', chi.fm)\n",
    "    #         print('\\nSSE', SSE)\n",
    "            if i < len(all_perms)-1:\n",
    "                SSE_c = 0\n",
    "                for j in range(np.size(test_d_c, 1)):\n",
    "                    chi_gmean_test_c = chi.chi_quad(test_d_c[:, j])\n",
    "                    SSE_c += (chi_gmean_test_c - test_label_gmean_c[j]) ** 2\n",
    "                SSEs_c[i, 3] = SSE_c / np.size(test_d_c)\n",
    "    #             print('\\nUnseen data SSE', SSE_c)\n",
    "\n",
    "\n",
    "    #         print('\\n\\n\\n')\n",
    "\n",
    "            SSEs_sum += SSEs\n",
    "            SSEs_c_sum += SSEs_c\n",
    "\n",
    "\n",
    "    SSEs_avg = SSEs_sum / num_epoch\n",
    "    SSEs_c_avg = SSEs_c_sum / num_epoch\n",
    "    \n",
    "    SSEs_avg_list.append(SSEs_avg)\n",
    "    SSEs_c_avg_list.append(SSEs_c_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "960e826b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "7\n",
      "11\n",
      "15\n",
      "19\n",
      "23\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "# 2, 6, 24, 120, 720\n",
    "num = 24\n",
    "step = 1\n",
    "if num > 6:\n",
    "    step = int(num / 6)\n",
    "for i in range(step-1, num, step):\n",
    "    print(i)\n",
    "for i in range(0, num):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9296723",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot error\n",
    "\n",
    "for i, (dim, SSEs_avg, SSEs_c_avg) in enumerate(zip(dim_list, SSEs_avg_list, SSEs_c_avg_list)):\n",
    "    num_perm = math.factorial(dim)\n",
    "    fig, ax = plt.subplots()\n",
    "    x = (np.asarray(list(range(1, num_perm+1)))) / num_perm\n",
    "    print(x.shape, SSEs_avg.shape)\n",
    "    print(x)\n",
    "#     print(SSEs_avg)\n",
    "    plt.plot(x, SSEs_avg)\n",
    "    ax.set_title('SSE (Data with same pattern)')\n",
    "    ax.legend(['Min', 'Max', 'Mean', 'Geometric Mean'])\n",
    "    ax.set_xlabel('Percentage of Seen Data')\n",
    "    ax.set_ylabel('SSEs avg')\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter('{0:.0%}'.format))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    x = (np.asarray(list(range(1, num_perm)))) / num_perm\n",
    "    print(x.shape, SSEs_c_avg.shape)\n",
    "    print(x)\n",
    "#     print(SSEs_c_avg)\n",
    "    plt.plot(x, SSEs_c_avg)\n",
    "    ax.set_title('SSE (Data with unseen pattern)')\n",
    "    ax.legend(['Min', 'Max', 'Mean', 'Geometric Mean'])\n",
    "    ax.set_xlabel('Percentage of Seen Data')\n",
    "    ax.set_ylabel('SSEs avg')\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter('{0:.0%}'.format))\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
